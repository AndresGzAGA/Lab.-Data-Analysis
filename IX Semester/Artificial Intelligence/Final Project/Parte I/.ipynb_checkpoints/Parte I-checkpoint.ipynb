{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "np.random.seed(1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10 #Usamos keras únicamente para importar la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparamos el conjunto de datos de CIFAR-10\n",
    "\n",
    "Aquí todo es muy similar a lo que ya se hizo en clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() #Arrays de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is (50000, 32, 32, 3)\n",
      "The shape of y_train is (50000, 1)\n",
      "\n",
      "The shape of x_test is (10000, 32, 32, 3)\n",
      "The shape of y_test is (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of x_train is', x_train.shape)\n",
    "print('The shape of y_train is', y_train.shape)\n",
    "\n",
    "print('\\nThe shape of x_test is', x_test.shape)\n",
    "print('The shape of y_test is', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los arreglos en x ya están en la forma requerida: (Batch, Coord_x, Coord_y, Canal)\n",
    "\n",
    "Igual los arreglos en y: (Batch, valor_esperado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos componer capas existentes dentro de una sola (por ejemplo convoluciones, batch normalization, etc.)\n",
    "#Este es un modelo de tres capas convolucionales, seguidas de su normalización y función de activación\n",
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super(ResnetIdentityBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters #Numero de filtros en cada capa\n",
    "    \n",
    "        #Aquí usamos capas ya existentes dadas por keras. En nuestro proyecto debemos crear nuestrar propias capas\n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1)) #Filtros de 1x1\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same') #Filtros de kernel_size x kernel_size\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1)) #Filtros de 1x1\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "    \n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "    \n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "    \n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3]) #kernelsize = 1 en la capa dos. 1, 2 y 3 filtros en cada capa respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = block(tf.zeros([1, 2, 3, 3])) #Hace una llamada de un input inicial para inicializar los parámetros con keras\n",
    "#Representaría un batch de una imagen 2D con 2x3 pixeles y 3 canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0xec0cf48>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x5b63988>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x5b8a0c8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x5b8a6c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x5b8ac88>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x5b91408>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'resnet_identity_block/conv2d/kernel:0' shape=(1, 1, 3, 1) dtype=float32, numpy=\n",
       " array([[[[-0.25452846],\n",
       "          [-0.62852454],\n",
       "          [ 0.34352624]]]], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/conv2d/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/batch_normalization/gamma:0' shape=(1,) dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/batch_normalization/beta:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/conv2d_1/kernel:0' shape=(1, 1, 1, 2) dtype=float32, numpy=array([[[[ 0.68507755, -0.04400742]]]], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/conv2d_1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/batch_normalization_1/gamma:0' shape=(2,) dtype=float32, numpy=array([1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/batch_normalization_1/beta:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/conv2d_2/kernel:0' shape=(1, 1, 2, 3) dtype=float32, numpy=\n",
       " array([[[[-0.04436231,  0.71217835, -0.47600722],\n",
       "          [-0.14561027, -0.61685026,  0.03429425]]]], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/conv2d_2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/batch_normalization_2/gamma:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'resnet_identity_block/batch_normalization_2/beta:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.trainable_variables\n",
    "#De aquí vemos que queras no sólo aplica una convolución a la imágen, sino que también le suma un bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_identity_block\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  8         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  12        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la documentación de tf sobre su función de convolución: https://www.tensorflow.org/api_docs/python/tf/nn/convolution\n",
    "\n",
    "tf.nn.convolution(input, filters, strides=None, padding='VALID', data_format=None,\n",
    "    dilations=None, name=None)\n",
    "#### Args\n",
    "\n",
    "-input: An (N+2)-D Tensor (1 <= N <= 3) of type T, of shape [batch_size] + input_spatial_shape + [in_channels] if data_format does not start with \"NC\" (default), or [batch_size, in_channels] + input_spatial_shape if data_format starts with \"NC\".\n",
    "\n",
    "    Nota: Con \"(N+2)-D tensor (1 <= N <= 3)\" se refiere a que el input debe de ser de rango 3, 4 o 5, dependiendo del orden de la convolución (3 para 1D, 4 para 2D y 5 para 3D).\n",
    "\n",
    "-filters: An (N+2)-D Tensor with the same type as input and shape spatial_filter_shape + [in_channels, out_channels].\n",
    "\n",
    "-padding: A string, either \"VALID\" or \"SAME\". The padding algorithm. \"valid\" means no padding. \"same\" results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input.\n",
    "\n",
    "-strides: Optional. Sequence of N ints >= 1. Specifies the output stride. Defaults to [1]*N. If any value of strides is > 1, then all values of dilation_rate must be 1.\n",
    "\n",
    "-dilations: Optional. Sequence of N ints >= 1. Specifies the filter upsampling/input downsampling rate. In the literature, the same parameter is sometimes called input stride or dilation. The effective filter size used for the convolution will be spatial_filter_shape + (spatial_filter_shape - 1) * (rate - 1), obtained by inserting (dilation_rate[i]-1) zeros between consecutive elements of the original filter in each spatial dimension i. If any value of dilation_rate is > 1, then all values of strides must be 1.\n",
    "\n",
    "-name: Optional name for the returned tensor.\n",
    "\n",
    "-data_format: A string or None. Specifies whether the channel dimension of the input and output is the last dimension (default, or if data_format does not start with \"NC\"), or the second dimension (if data_format starts with \"NC\"). For N=1, the valid values are \"NWC\" (default) and \"NCW\". For N=2, the valid values are \"NHWC\" (default) and \"NCHW\". For N=3, the valid values are \"NDHWC\" (default) and \"NCDHW\".\n",
    "\n",
    "#### Returns\n",
    "A Tensor with the same type as input of shape\n",
    "[batch_size] + output_spatial_shape + [out_channels]\n",
    "\n",
    "if data_format is None or does not start with \"NC\", or\n",
    "\n",
    "[batch_size, out_channels] + output_spatial_shape\n",
    "\n",
    "if data_format starts with \"NC\", where output_spatial_shape depends on the value of padding.\n",
    "\n",
    "If padding == \"SAME\": output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i])\n",
    "\n",
    "If padding == \"VALID\": output_spatial_shape[i] = ceil((input_spatial_shape[i] - (spatial_filter_shape[i]-1) * dilation_rate[i]) / strides[i])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro convolucional en 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparando un input de juguete con el rango apropiado\n",
    "channels = 3\n",
    "x = tf.constant(tf.random.normal((10,100,channels))) #10 \"Imagenes\" en 1D con 100 pixeles y 3 canales (tensor constante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Módulo de convolución en 1D creado por mi\n",
    "#Hecho para que se inicializen las variables con las dimensiones apropiadas la primera vez que lo llamas\n",
    "class SimpleConv1D(tf.Module):\n",
    "    def __init__(self, num_filters, dim_filters, strides = None, padding=\"VALID\",\n",
    "               data_format=None,dilations=None, name=\"SimpleConv1D\"):\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False\n",
    "        self.num_filters = num_filters #Number of filters\n",
    "        self.dim_filters = dim_filters #Dimension of each filter (length of filter in 1D)\n",
    "        self.strides = strides #stride of filters\n",
    "        self.padding = padding #padding (VALID or SAME)\n",
    "        self.data_format = data_format #Default: los canales están en el último índice del input, NC: En el segundo índice\n",
    "        self.dilations = dilations \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            # Create variables on first call.\n",
    "            self.x_len = len(x) #Length of the batch\n",
    "            self.chan_in = len(x[0][0]) #number of input channels\n",
    "            self.filters = tf.Variable(tf.random.normal([self.dim_filters,self.chan_in,self.num_filters]), name='filters') #Matriz con (num_filters) de filtros con dimensión (dim_filters) con valores iniciales random\n",
    "            self.is_built = True\n",
    "    \n",
    "        y = tf.nn.convolution(x, self.filters, strides=self.strides, padding=self.padding, data_format=self.data_format, dilations=self.dilations)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding: SAME\n",
    "#Strides: 2\n",
    "my_model = SimpleConv1D(num_filters = 2, dim_filters = 5, strides = 2, padding=\"SAME\")\n",
    "#num_filters = 2 también se puede pensar como los canales de salida\n",
    "#Es decir, aunque los canales de entrada sean 3, al poner 2 filtros, los canales de salida serán 2\n",
    "#tensorflow no es muy descriptivo sobre este proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = my_model(x) #Al llamar el modelo por primera vez se inicializan las variables con las dimensiones apropiadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 100, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 50, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape #2 canales de salida (2 filtros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'filters:0' shape=(5, 3, 2) dtype=float32, numpy=\n",
       " array([[[ 6.5578359e-01,  1.9488366e-02],\n",
       "         [-1.8042090e+00, -2.3391197e+00],\n",
       "         [ 1.3512541e+00,  7.0775205e-01]],\n",
       " \n",
       "        [[-7.4898705e-02, -1.9818981e-01],\n",
       "         [ 8.0385858e-01, -4.7230828e-01],\n",
       "         [-5.9183878e-01,  5.4109699e-01]],\n",
       " \n",
       "        [[-8.0509520e-01,  2.6159438e-01],\n",
       "         [ 8.1909361e-04,  1.1336755e-01],\n",
       "         [ 5.6337994e-01,  7.8079963e-01]],\n",
       " \n",
       "        [[ 1.3921384e+00,  8.5524035e-01],\n",
       "         [ 3.0346665e-01, -1.7680718e-01],\n",
       "         [ 3.1069374e+00, -1.0247805e+00]],\n",
       " \n",
       "        [[-6.9348264e-01,  9.0537935e-01],\n",
       "         [ 7.0930481e-01, -1.1760243e+00],\n",
       "         [-1.2881032e+00,  8.1570160e-01]]], dtype=float32)>,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.trainable_variables #2 filtros para 3 canales con longitud 5 de cada filtro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ahora hacemos un filtro conv 1D con bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Módulo de convolución en 1D creado por mi\n",
    "#Hecho para que se inicializen las variables con las dimensiones apropiadas la primera vez que lo llamas\n",
    "class Conv1D(tf.Module):\n",
    "    def __init__(self, num_filters, dim_filters, strides = None, padding=\"VALID\",\n",
    "               data_format=None,dilations=None, name=\"Conv1D\"):\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False\n",
    "        self.num_filters = num_filters #Number of filters\n",
    "        self.dim_filters = dim_filters #Dimension of each filter (length of filter in 1D)\n",
    "        self.strides = strides #stride of filters\n",
    "        self.padding = padding #padding (VALID or SAME)\n",
    "        self.data_format = data_format #Default: los canales están en el último índice del input, NC: En el segundo índice\n",
    "        self.dilations = dilations \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            # Create variables on first call.\n",
    "            self.chan_in = len(x[0][0]) #number of input channels\n",
    "            self.filters = tf.Variable(tf.random.normal([self.dim_filters,self.chan_in,self.num_filters]), name='filters') #Matriz con (num_filters) de filtros con dimensión (dim_filters) con valores iniciales random\n",
    "            self.b = tf.Variable(tf.zeros([self.num_filters]), name='b') #un bias por cada canal de salida\n",
    "            self.is_built = True\n",
    "    \n",
    "        y = tf.nn.convolution(x, self.filters, strides=self.strides, padding=self.padding, data_format=self.data_format, dilations=self.dilations)\n",
    "        return y+self.b #tensorflow empaqueta apropiadamente la suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding: SAME\n",
    "#Strides: 2\n",
    "my_model = Conv1D(num_filters = 2, dim_filters = 5, strides = 2, padding=\"SAME\")\n",
    "#num_filters = 2 canales de salida. Se espera un bias de 2 parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = my_model(x) #Al llamar el modelo por primera vez se inicializan las variables con las dimensiones apropiadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 50, 2])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape #2 canales de salida (2 filtros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'filters:0' shape=(5, 3, 2) dtype=float32, numpy=\n",
       " array([[[ 0.28205597,  0.06666595],\n",
       "         [-0.38943884, -0.6586265 ],\n",
       "         [ 0.4944333 ,  0.2423875 ]],\n",
       " \n",
       "        [[-1.2382549 ,  0.9412981 ],\n",
       "         [-0.09423573, -2.0693648 ],\n",
       "         [ 0.0581377 ,  1.1383051 ]],\n",
       " \n",
       "        [[ 0.23250592, -0.08657692],\n",
       "         [-0.5052997 , -0.6854154 ],\n",
       "         [-0.945686  , -1.398479  ]],\n",
       " \n",
       "        [[-0.99099374, -1.0664659 ],\n",
       "         [-0.55181396, -0.2996886 ],\n",
       "         [-2.3998063 , -2.0952628 ]],\n",
       " \n",
       "        [[-1.2854909 ,  0.751362  ],\n",
       "         [ 0.6831971 , -1.1918267 ],\n",
       "         [ 1.0357122 , -0.4723644 ]]], dtype=float32)>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.trainable_variables #2 filtros para 3 canales con longitud 5 de cada filtro y 2 bias (uno por cada filtro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro convolucional en 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparando un input de juguete con el rango apropiado\n",
    "channels = 3\n",
    "x = tf.constant(tf.random.normal((10,100,100,channels))) #10 \"Imagenes\" en 2D con 100x100 pixeles y 3 canales (tensor constante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Módulo de convolución en 2D creado por mi\n",
    "#Hecho para que se inicializen las variables con las dimensiones apropiadas la primera vez que lo llamas\n",
    "class Conv2D(tf.Module):\n",
    "    def __init__(self, num_filters, dim_filters, strides = None, padding=\"VALID\",\n",
    "               data_format=None,dilations=None, name=\"Conv2D\"):\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False\n",
    "        self.num_filters = num_filters #Number of filters\n",
    "        self.dim_filters = dim_filters #Dimension of each filter (tuple of length 2)\n",
    "        self.strides = strides #stride of filters\n",
    "        self.padding = padding #padding (VALID or SAME)\n",
    "        self.data_format = data_format #Default: los canales están en el último índice del input, NC: En el segundo índice\n",
    "        self.dilations = dilations \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            # Create variables on first call.\n",
    "            self.chan_in = len(x[0][0][0]) #number of input channels\n",
    "            self.filters = tf.Variable(tf.random.normal([self.dim_filters[0],self.dim_filters[1],self.chan_in,self.num_filters]), name='filters') #Matriz con (num_filters) de filtros con dimensión (dim_filters) con valores iniciales random\n",
    "            self.b = tf.Variable(tf.zeros([self.num_filters]), name='b') #un bias por cada canal de salida\n",
    "            self.is_built = True\n",
    "    \n",
    "        y = tf.nn.convolution(x, self.filters, strides=self.strides, padding=self.padding, data_format=self.data_format, dilations=self.dilations)\n",
    "        return y+self.b #tensorflow empaqueta apropiadamente la suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding: SAME\n",
    "#Strides: 2\n",
    "my_model = Conv2D(num_filters = 2, dim_filters = (5,5), strides = (2,4), padding=\"SAME\")\n",
    "#las dimensiones de los filtros ahora deben ser una 2-tupla\n",
    "#El stride puede ser una 2-tupla o una constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = my_model(x) #Al llamar el modelo por primera vez se inicializan las variables con las dimensiones apropiadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 50, 25, 2])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape #2 canales de salida (2 filtros) #El stride de un lado es el doble que en el otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'filters:0' shape=(5, 5, 3, 2) dtype=float32, numpy=\n",
       " array([[[[ 3.69655490e-01,  8.80957305e-01],\n",
       "          [ 1.36734748e+00,  4.21335408e-03],\n",
       "          [ 2.88816333e-01,  1.29711497e+00]],\n",
       " \n",
       "         [[-5.71852207e-01,  1.88900813e-01],\n",
       "          [-9.45197582e-01,  4.63461936e-01],\n",
       "          [ 4.11679298e-01,  5.96832335e-01]],\n",
       " \n",
       "         [[-1.41681683e+00,  6.23673677e-01],\n",
       "          [-1.30378354e+00, -5.45252144e-01],\n",
       "          [ 3.09176415e-01,  4.18514401e-01]],\n",
       " \n",
       "         [[-6.52245641e-01, -5.85247912e-02],\n",
       "          [ 3.37797433e-01, -3.87613058e-01],\n",
       "          [-7.99519658e-01, -2.57570028e-01]],\n",
       " \n",
       "         [[-1.24170506e+00,  1.36045015e+00],\n",
       "          [-3.42234224e-02, -4.23214972e-01],\n",
       "          [ 1.63763952e+00, -8.41593683e-01]]],\n",
       " \n",
       " \n",
       "        [[[-7.84324575e-03,  3.58142778e-02],\n",
       "          [-7.66188264e-01, -6.88538730e-01],\n",
       "          [-4.18926239e-01, -1.20964134e+00]],\n",
       " \n",
       "         [[-5.28907299e-01,  1.00093126e+00],\n",
       "          [ 1.39255166e+00, -1.07857931e+00],\n",
       "          [-3.38135809e-01,  5.64456224e-01]],\n",
       " \n",
       "         [[-4.77984756e-01,  2.99219429e-01],\n",
       "          [ 3.98074806e-01, -1.02507722e+00],\n",
       "          [ 8.78257394e-01,  3.73982012e-01]],\n",
       " \n",
       "         [[ 4.10153776e-01,  1.08609474e+00],\n",
       "          [ 3.18262488e-01, -1.44086480e+00],\n",
       "          [ 5.84014893e-01, -4.71713483e-01]],\n",
       " \n",
       "         [[-5.24241030e-01,  7.99947917e-01],\n",
       "          [ 6.32005215e-01, -8.25127721e-01],\n",
       "          [ 1.93336570e+00,  1.42206228e+00]]],\n",
       " \n",
       " \n",
       "        [[[ 1.39508235e+00, -8.68197083e-01],\n",
       "          [ 1.56619430e+00, -1.78147697e+00],\n",
       "          [ 9.12164524e-03, -5.82810380e-02]],\n",
       " \n",
       "         [[-3.49024311e-04, -1.29051208e+00],\n",
       "          [ 3.29283506e-01, -8.77906442e-01],\n",
       "          [-1.04333282e+00,  6.86896265e-01]],\n",
       " \n",
       "         [[-1.41007173e+00,  8.77942860e-01],\n",
       "          [ 4.02544111e-01,  1.32668817e+00],\n",
       "          [ 3.92605335e-01, -2.25521192e-01]],\n",
       " \n",
       "         [[-1.54172564e+00, -5.80799460e-01],\n",
       "          [ 1.14746958e-01, -2.55260728e-02],\n",
       "          [ 1.58923042e+00,  2.39375257e+00]],\n",
       " \n",
       "         [[-4.96837735e-01, -2.69335002e-01],\n",
       "          [ 6.15998983e-01, -1.24596484e-01],\n",
       "          [ 1.12762845e+00,  4.65079337e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 7.69965708e-01,  1.67666510e-01],\n",
       "          [ 2.23454461e-02, -9.88867104e-01],\n",
       "          [-1.21719515e+00,  1.01544833e+00]],\n",
       " \n",
       "         [[ 6.61531985e-01, -6.41816616e-01],\n",
       "          [ 1.98503590e+00, -1.00420034e-02],\n",
       "          [ 2.97072679e-01,  9.73239124e-01]],\n",
       " \n",
       "         [[-6.21026039e-01, -1.15759909e-01],\n",
       "          [-1.07578784e-01, -5.17772436e-01],\n",
       "          [ 1.46785235e+00,  1.53534687e+00]],\n",
       " \n",
       "         [[ 1.54527891e+00, -9.88397062e-01],\n",
       "          [ 7.83967555e-01,  7.26925313e-01],\n",
       "          [-1.95672846e+00,  2.47735810e-02]],\n",
       " \n",
       "         [[-2.56540507e-01, -4.04518902e-01],\n",
       "          [ 1.03078437e+00,  7.21120954e-01],\n",
       "          [-1.57712698e+00, -1.41610458e-01]]],\n",
       " \n",
       " \n",
       "        [[[-1.74118447e+00, -8.57837796e-01],\n",
       "          [ 8.78454268e-01, -1.96642935e-01],\n",
       "          [ 2.43662858e+00, -7.53942490e-01]],\n",
       " \n",
       "         [[ 4.51220423e-02,  1.26051795e+00],\n",
       "          [ 9.99281645e-01, -1.54698640e-01],\n",
       "          [-1.14939940e+00, -8.25066626e-01]],\n",
       " \n",
       "         [[-2.12982440e+00,  3.39567751e-01],\n",
       "          [ 4.34459060e-01,  8.11313614e-02],\n",
       "          [-3.98320079e-01, -3.91318381e-01]],\n",
       " \n",
       "         [[ 4.40044142e-02,  3.39533001e-01],\n",
       "          [-8.89583111e-01,  9.11568880e-01],\n",
       "          [-1.12702274e+00,  1.13659334e+00]],\n",
       " \n",
       "         [[-1.20135844e+00, -1.16470635e+00],\n",
       "          [-3.22127849e-01,  5.50654709e-01],\n",
       "          [-3.44603926e-01,  1.95316240e-01]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.trainable_variables #2 filtros para 3 canales con dimensión 5x5 de cada filtro y 2 bias (uno por cada filtro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization\n",
    "\n",
    "tf.nn.batch_normalization(x, mean, variance, offset, scale, variance_epsilon, name=None)\n",
    "\n",
    "Normalizes a tensor by mean and variance, and applies (optionally) a scale $\\gamma$ to it, as well as an offset $\\beta$:\n",
    "\n",
    "$\\frac{\\gamma(x-\\mu)}{\\sigma}+\\beta$\n",
    "\n",
    "mean, variance, offset and scale are all expected to be of one of two shapes:\n",
    "\n",
    "-In all generality, they can have the same number of dimensions as the input x, with identical sizes as x for the dimensions that are not normalized over (the 'depth' dimension(s)), and dimension 1 for the others which are being normalized over. mean and variance in this case would typically be the outputs of tf.nn.moments(..., keepdims=True) during training, or running averages thereof during inference.\n",
    "\n",
    "-In the common case where the 'depth' dimension is the last dimension in the input tensor x, they may be one dimensional tensors of the same size as the 'depth' dimension. This is the case for example for the common [batch, depth] layout of fully-connected layers, and [batch, height, width, depth] for convolutions. mean and variance in this case would typically be the outputs of tf.nn.moments(..., keepdims=False) during training, or running averages thereof during inference.\n",
    "\n",
    "#### Args\n",
    "-x\tInput Tensor of arbitrary dimensionality.\n",
    "\n",
    "-mean\tA mean Tensor.\n",
    "\n",
    "-variance\tA variance Tensor.\n",
    "\n",
    "-offset\tAn offset Tensor, often denoted  in equations, or None. If present, will be added to the normalized tensor.\n",
    "\n",
    "-scale\tA scale Tensor, often denoted  in equations, or None. If present, the scale is applied to the normalized tensor.\n",
    "\n",
    "-variance_epsilon\tA small float number to avoid dividing by 0.\n",
    "\n",
    "-name\tA name for this operation (optional).\n",
    "\n",
    "#### Returns\n",
    "the normalized, scaled, offset tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparando un input de juguete con el rango apropiado\n",
    "channels = 3\n",
    "x_1D = tf.constant(tf.random.normal((10,100,channels))) #10 \"Imagenes\" en 1D con 100 pixeles y 3 canales (tensor constante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparando un input de juguete con el rango apropiado\n",
    "channels = 3\n",
    "x_2D = tf.constant(tf.random.normal((10,100,100,channels))) #10 \"Imagenes\" en 2D con 100x100 pixeles y 3 canales (tensor constante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Módulo de batch normalization en 1D o 2D creado por mi\n",
    "#Hecho para que se inicializen las variables con las dimensiones apropiadas la primera vez que lo llamas\n",
    "#Usaremos el segundo tipo de shape descrito en la documentación, que es el más común\n",
    "#En este se asume que el primer índice es el de cada imágen en el batch, los siguientes son los espaciales, y el último es el canal\n",
    "class BatchNormalization(tf.Module):\n",
    "    def __init__(self, name=\"Batch_Normalization\"):\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            #Create variables on first call.\n",
    "            self.x_dim =len(x.shape) #Determina la dimensionalidad del tensor x a normalizar\n",
    "            if self.x_dim == 3: #imágen en 1D\n",
    "                self.chan_in = len(x[0][0]) #number of input channels\n",
    "                self.axes = [0,1]\n",
    "            elif self.x_dim == 4: #imágen en 2D\n",
    "                self.chan_in = len(x[0][0][0]) #number of input channels\n",
    "                self.axes = [0,1,2]\n",
    "            else:\n",
    "                print(\"ERROR: Dimensionalidad incorrecta en x\")\n",
    "            self.beta = tf.Variable(tf.zeros([self.chan_in]), name='b') #un offset por cada canal de salida\n",
    "            self.gamma = tf.Variable(tf.ones([self.chan_in]), name='gamma') #un scale por cada canal de salida\n",
    "            self.is_built = True\n",
    "        \n",
    "        self.mean, self.variance = tf.nn.moments(x, axes=self.axes, shift=None, keepdims=False, name=None)\n",
    "        y = tf.nn.batch_normalization(x, self.mean, self.variance, self.beta, self.gamma, variance_epsilon=1e-10, name=None)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm_1D = BatchNormalization()\n",
    "y_1D = Norm_1D(x_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 3)\n",
      "(10, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "#El shape se mantiene\n",
    "print(x_1D.shape)\n",
    "print(y_1D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'gamma:0' shape=(3,) dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Norm_1D.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 1.1324882e-08,  3.2186509e-09, -1.2516975e-08], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.0000006, 1.0000006, 1.       ], dtype=float32)>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_1D si se normaliza en los 3 canales\n",
    "tf.nn.moments(y_1D, axes=[0,1], shift=None, keepdims=False, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm_2D = BatchNormalization()\n",
    "y_2D = Norm_2D(x_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 100, 3)\n",
      "(10, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "#El shape se mantiene\n",
    "print(x_2D.shape)\n",
    "print(y_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-1.9154548e-08, -2.8183461e-08, -7.2121620e-10], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.0000035 , 0.99999905, 0.99999416], dtype=float32)>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_2D si se normaliza en los 3 canales\n",
    "tf.nn.moments(y_2D, axes=[0,1,2], shift=None, keepdims=False, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool\n",
    "\n",
    "tf.nn.avg_pool(input, ksize, strides, padding, data_format=None, name=None)\n",
    "\n",
    "Each entry in output is the mean of the corresponding size ksize window in value.\n",
    "\n",
    "#### Args\n",
    "\n",
    "-input\tTensor of rank N+2, of shape [batch_size] + input_spatial_shape + [num_channels] if data_format does not start with \"NC\" (default), or [batch_size, num_channels] + input_spatial_shape if data_format starts with \"NC\". Pooling happens over the spatial dimensions only.\n",
    "\n",
    "-ksize\tAn int or list of ints that has length 1, N or N+2. The size of the window for each dimension of the input tensor.\n",
    "\n",
    "-strides\tAn int or list of ints that has length 1, N or N+2. The stride of the sliding window for each dimension of the input tensor.\n",
    "\n",
    "-padding\tA string, either 'VALID' or 'SAME'. The padding algorithm. See the \"returns\" section of tf.nn.convolution for details.\n",
    "\n",
    "-data_format\tA string. Specifies the channel dimension. For N=1 it can be either \"NWC\" (default) or \"NCW\", for N=2 it can be either \"NHWC\" (default) or \"NCHW\" and for N=3 either \"NDHWC\" (default) or \"NCDHW\".\n",
    "\n",
    "-name\tOptional name for the operation.\n",
    "\n",
    "#### Returns\n",
    "A Tensor of format specified by data_format. The average pooled output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Módulo de Average Pooling 1D o 2D creado por mi\n",
    "#Hecho para que se inicializen las variables con las dimensiones apropiadas la primera vez que lo llamas\n",
    "class AvgPool(tf.Module):\n",
    "    def __init__(self, dim_filter, strides = None, padding=\"VALID\",\n",
    "               data_format=None, name=\"Average_Pooling\"):\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False\n",
    "        self.dim_filter = dim_filter #Dimension of each filter (escalar en 1D, 2-tupla en 2D)\n",
    "        self.strides = strides #stride of filters\n",
    "        self.padding = padding #padding (VALID or SAME)\n",
    "        self.data_format = data_format #Default: los canales están en el último índice del input, NC: En el segundo índice\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            # Create variables on first call.\n",
    "            self.x_dim =len(x.shape) #Determina la dimensionalidad del tensor x a normalizar\n",
    "            if self.x_dim == 3: #imágen en 1D\n",
    "                self.ksize = [1,self.dim_filter,1]\n",
    "            elif self.x_dim == 4: #imágen en 2D\n",
    "                self.ksize = [1,self.dim_filter[0],self.dim_filter[1],1]\n",
    "            else:\n",
    "                print(\"ERROR: Dimensionalidad incorrecta en x\")\n",
    "            self.is_built = True\n",
    "    \n",
    "        y = tf.nn.avg_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding, data_format=self.data_format, name=None)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg_1D = AvgPool(dim_filter = 5, strides = 2, padding=\"VALID\")\n",
    "y_1D = Avg_1D(x_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 3)\n",
      "(10, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "#El promedio se realiza en las coordenadas espaciales\n",
    "print(x_1D.shape)\n",
    "print(y_1D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg_2D = AvgPool(dim_filter = (5,5), strides = (2,4), padding=\"VALID\", data_format=None, name=None)\n",
    "y_2D = Avg_2D(x_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 100, 3)\n",
      "(10, 48, 24, 3)\n"
     ]
    }
   ],
   "source": [
    "#El promedio se realiza en las coordenadas espaciales\n",
    "#El stride en una dirección es el doble que en la otra\n",
    "print(x_2D.shape)\n",
    "print(y_2D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentación: https://www.tensorflow.org/api_docs/python/tf/nn/max_pool\n",
    "\n",
    "tf.nn.max_pool(input, ksize, strides, padding, data_format=None, name=None)\n",
    "\n",
    "#### Args\n",
    "\n",
    "-input\tTensor of rank N+2, of shape [batch_size] + input_spatial_shape + [num_channels] if data_format does not start with \"NC\" (default), or [batch_size, num_channels] + input_spatial_shape if data_format starts with \"NC\". Pooling happens over the spatial dimensions only.\n",
    "\n",
    "-ksize\tAn int or list of ints that has length 1, N or N+2. The size of the window for each dimension of the input tensor.\n",
    "\n",
    "-strides\tAn int or list of ints that has length 1, N or N+2. The stride of the sliding window for each dimension of the input tensor.\n",
    "\n",
    "-padding\tEither the string\"SAME\"or\"VALID\"indicating the type of padding algorithm to use, or a list indicating the explicit paddings at the start and end of each dimension. When explicit padding is used and data_format is\"NHWC\", this should be in the form[[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]]. When explicit padding used and data_format is\"NCHW\", this should be in the form[[0, 0], [0, 0], [pad_top, pad_bottom], [pad_left, pad_right]]. When using explicit padding, the size of the paddings cannot be greater than the sliding window size.\n",
    "\n",
    "-data_format   A string. Specifies the channel dimension. For N=1 it can be either \"NWC\" (default) or \"NCW\", for N=2 it can be either \"NHWC\" (default) or \"NCHW\" and for N=3 either \"NDHWC\" (default) or \"NCDHW\".\n",
    "\n",
    "-name\tOptional name for the operation.\n",
    "    \n",
    "#### Returns\n",
    "A Tensor of format specified by data_format. The max pooled output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Módulo de Average Pooling 1D o 2D creado por mi\n",
    "#Hecho para que se inicializen las variables con las dimensiones apropiadas la primera vez que lo llamas\n",
    "class MaxPool(tf.Module):\n",
    "    def __init__(self, dim_filter, strides = None, padding=\"VALID\",\n",
    "               data_format=None, name=\"Max_Pooling\"):\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False\n",
    "        self.dim_filter = dim_filter #Dimension of each filter (escalar en 1D, 2-tupla en 2D)\n",
    "        self.strides = strides #stride of filters\n",
    "        self.padding = padding #padding (VALID or SAME)\n",
    "        self.data_format = data_format #Default: los canales están en el último índice del input, NC: En el segundo índice\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            # Create variables on first call.\n",
    "            self.x_dim =len(x.shape) #Determina la dimensionalidad del tensor x a normalizar\n",
    "            if self.x_dim == 3: #imágen en 1D\n",
    "                self.ksize = [1,self.dim_filter,1]\n",
    "            elif self.x_dim == 4: #imágen en 2D\n",
    "                self.ksize = [1,self.dim_filter[0],self.dim_filter[1],1]\n",
    "            else:\n",
    "                print(\"ERROR: Dimensionalidad incorrecta en x\")\n",
    "            self.is_built = True\n",
    "    \n",
    "        y = tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding, data_format=self.data_format, name=None)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_1D = MaxPool(dim_filter = 5, strides = 2, padding=\"VALID\")\n",
    "y_1D = Max_1D(x_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 3)\n",
      "(10, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "#El máximo se toma de las coordenadas espaciales\n",
    "print(x_1D.shape)\n",
    "print(y_1D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_2D = MaxPool(dim_filter = (5,5), strides = (2,4), padding=\"VALID\", data_format=None, name=None)\n",
    "y_2D = Max_2D(x_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 100, 3)\n",
      "(10, 48, 24, 3)\n"
     ]
    }
   ],
   "source": [
    "#El promedio se realiza en las coordenadas espaciales\n",
    "#El stride en una dirección es el doble que en la otra\n",
    "print(x_2D.shape)\n",
    "print(y_2D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/nn/relu\n",
    "\n",
    "tf.nn.relu(features, name=None)\n",
    "\n",
    "#### Args\n",
    "-features\tA Tensor. Must be one of the following types: float32, float64, int32, uint8, int16, int8, int64, bfloat16, uint16, half, uint32, uint64, qint8.\n",
    "-name\tA name for the operation (optional).\n",
    "#### Returns\n",
    "A Tensor. Has the same type as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de activación relu creada por mi\n",
    "class Relu(tf.Module):\n",
    "    def __init__(self, name=\"Relu\"):\n",
    "        super().__init__(name=name)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return tf.nn.relu(x, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = Relu()\n",
    "y_2D = activation(x_2D) #Funciona en cualquier dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 100, 3)\n",
      "(10, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "#Se conserva el shape\n",
    "print(x_2D.shape)\n",
    "print(y_2D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/nn/softmax\n",
    "\n",
    "tf.nn.softmax(logits, axis=None, name=None)\n",
    "\n",
    "This function performs the equivalent of\n",
    "\n",
    "softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "\n",
    "#### Args\n",
    "-logits\tA non-empty Tensor. Must be one of the following types: half, float32, float64.\n",
    "\n",
    "-axis\tThe dimension softmax would be performed on. The default is -1 which indicates the last dimension.\n",
    "\n",
    "-name\tA name for the operation (optional).\n",
    "#### Returns\n",
    "-A Tensor. Has the same type and shape as logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de activación relu creada por mi\n",
    "class SoftMax(tf.Module):\n",
    "    def __init__(self, name=\"SoftMax\"):\n",
    "        super().__init__(name=name)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return tf.nn.softmax(x) #axis -1 por default por ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = SoftMax()\n",
    "y_2D = activation(x_2D) #Funciona en cualquier dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 100, 3)\n",
      "(10, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "#Se conserva el shape\n",
    "print(x_2D.shape)\n",
    "print(y_2D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulos de redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/compat/v1/layers/Flatten\n",
    "\n",
    "tf.compat.v1.layers.Flatten(data_format=None, **kwargs)\n",
    "\n",
    "Flattens an input tensor while preserving the batch axis (axis 0).\n",
    "\n",
    "#### Arguments\n",
    "-inputs\tTensor input.\n",
    "\n",
    "-name\tThe name of the layer (string).\n",
    "\n",
    "-data_format\tA string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, height, width).\n",
    "#### Returns\n",
    "Reshaped tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(tf.Module):\n",
    "    def __init__(self, name=\"Flatten\"):\n",
    "        super().__init__(name=name)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return tf.compat.v1.layers.Flatten()(x) #El primer paréntesis es para llamar a la función, el segundo es evaluarla en x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = Flatten()\n",
    "y = flat(x_2D) #Funciona en cualquier dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 100, 3)\n",
      "(10, 30000)\n"
     ]
    }
   ],
   "source": [
    "#Funciona\n",
    "print(x_2D.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Ver FlexibleDenseModule en notebook IntroTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.Module):\n",
    "    # Note: No need for `in+features`\n",
    "    def __init__(self, out_features, activation = \"relu\" ,name=\"Dense\"):\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False\n",
    "        self.out_features = out_features\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Create variables on first call.\n",
    "        if not self.is_built:\n",
    "            self.w = tf.Variable(tf.random.normal([x.shape[-1], self.out_features]), name='w')\n",
    "            self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n",
    "            self.is_built = True\n",
    "\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        if activation == \"relu\":\n",
    "            return tf.nn.relu(y)\n",
    "        elif activation == \"softmax\":\n",
    "            return tf.nn.softmax(y)\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Min_Cuad(target_y, predicted_y): #Minimos cuadrados\n",
    "    return tf.reduce_mean(tf.square(target_y - predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haremos un objeto Sequential que ya sirva para unir los módulos de manera secuencial en un modelo entrenable y con algunas propiedades útiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(tf.Module): #Hereda las propiedades de tf.Module\n",
    "    def __init__(self,layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.is_built = False\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        #Las capas se llaman de manera Secuencial\n",
    "        if not self.is_built:\n",
    "            self.input_example = x\n",
    "            self.input_shape = x.shape\n",
    "            self.is_built = True\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "        \n",
    "    def trainable_parameters(self):\n",
    "        if not self.is_built:\n",
    "            print(\"Error: No has inicializado las variables\")\n",
    "        else:\n",
    "            t_par = 0\n",
    "            for var in self.trainable_variables:\n",
    "                t_par += var.numpy().size\n",
    "            return t_par\n",
    "    \n",
    "    def summary(self):\n",
    "        if not self.is_built:\n",
    "            print(\"Error: No has inicializado las variables\")\n",
    "        else:\n",
    "            x = self.input_example\n",
    "            s = \" \"\n",
    "            space = 25\n",
    "            shape_str = \"\"\n",
    "            for i in self.input_shape[1:]:\n",
    "                shape_str += \", \"+str(i) \n",
    "            print(\"Model: Secuential with \"+str(len(self.layers))+\" layers.\")\n",
    "            print(\"Input shape: (Batch\"+shape_str+\")\")\n",
    "            print(75*\"-\")\n",
    "            print(\"Layer\"+(space-5)*s+\"Output shape\"+(space-12)*s+\"Trainable paramaterers\")\n",
    "            print(75*\"=\")\n",
    "            for layer in self.layers:\n",
    "                x = layer(x)\n",
    "                shape_str = \"\"\n",
    "                for i in x.shape[1:]:\n",
    "                    shape_str += \", \"+str(i)\n",
    "                t_param_layer = 0\n",
    "                for var in layer.trainable_variables:\n",
    "                    t_param_layer += var.numpy().size\n",
    "                print(layer.name+(space-len(layer.name))*s+\"(Batch\"+shape_str+\")\"+(space+3-len(shape_str))*s+str(t_param_layer))\n",
    "                print(75*\"-\")\n",
    "            print(\"Total trainable parameters: \"+str(self.trainable_parameters()))\n",
    "\n",
    "    def compile(self, optimizer=\"Gradient\", loss=Min_Cuad, metrics=\"acuracy\"):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        self.compiled = True\n",
    "        #model.compile(optimizer='adam',\n",
    "        #      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        #      metrics=['accuracy'])\n",
    "    \n",
    "    def train(self, x, y, learning_rate):\n",
    "        if not self.compiled:\n",
    "            print(\"ERROR: Se necesita compilar el modelo.\")\n",
    "        \n",
    "        with tf.GradientTape() as t:\n",
    "            # Trainable variables are automatically tracked by GradientTape\n",
    "            current_loss = self.loss(y, self(x))\n",
    "        \n",
    "        if self.optimizer ==\"Gradient\":\n",
    "            for var in self.variables:\n",
    "                d_var = t.gradient(current_loss, [var])\n",
    "                var.assign_sub(learning_rate*d_var)\n",
    "        else:\n",
    "            print(\"ERROR: Optimizador no reconocido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Conv2D(num_filters = 3, dim_filters = (2,2), strides = (2,2), padding=\"SAME\"),\n",
    "    BatchNormalization(),\n",
    "    AvgPool(dim_filter = (3,3), strides = (2,2), padding=\"VALID\"),\n",
    "    Conv2D(num_filters = 2, dim_filters = (5,5), strides = (2,4), padding=\"SAME\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool(dim_filter = (3,3), strides = (2,2), padding=\"VALID\"),\n",
    "    Flatten(),\n",
    "    Dense(out_features = 50, activation = \"relu\"),\n",
    "    tf.compat.v1.layers.Dropout(rate=0.1, name=\"Dropout\"),\n",
    "    Dense(out_features = 30, activation = \"relu\"),\n",
    "    tf.compat.v1.layers.Dropout(rate=0.1, name=\"Dropout\"),\n",
    "]\n",
    "\n",
    "My_Model = Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2D = My_Model(x_2D) #Inicializamos las variables con el Batch de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Secuential with 11 layers.\n",
      "Input shape: (Batch, 100, 100, 3)\n",
      "---------------------------------------------------------------------------\n",
      "Layer                    Output shape             Trainable paramaterers\n",
      "===========================================================================\n",
      "Conv2D                   (Batch, 50, 50, 3)                 39\n",
      "---------------------------------------------------------------------------\n",
      "Batch_Normalization      (Batch, 50, 50, 3)                 6\n",
      "---------------------------------------------------------------------------\n",
      "Average_Pooling          (Batch, 24, 24, 3)                 0\n",
      "---------------------------------------------------------------------------\n",
      "Conv2D                   (Batch, 12, 6, 2)                  152\n",
      "---------------------------------------------------------------------------\n",
      "Batch_Normalization      (Batch, 12, 6, 2)                  4\n",
      "---------------------------------------------------------------------------\n",
      "Max_Pooling              (Batch, 5, 2, 2)                   0\n",
      "---------------------------------------------------------------------------\n",
      "Flatten                  (Batch, 20)                        0\n",
      "---------------------------------------------------------------------------\n",
      "Dense                    (Batch, 50)                        1050\n",
      "---------------------------------------------------------------------------\n",
      "Dropout                  (Batch, 50)                        0\n",
      "---------------------------------------------------------------------------\n",
      "Dense                    (Batch, 30)                        1530\n",
      "---------------------------------------------------------------------------\n",
      "Dropout                  (Batch, 30)                        0\n",
      "---------------------------------------------------------------------------\n",
      "Total trainable parameters: 2781\n"
     ]
    }
   ],
   "source": [
    "My_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
