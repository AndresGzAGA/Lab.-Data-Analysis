{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "\n",
    "# Tarea 6\n",
    "\n",
    "### Implementar una red neuronal de convolución usando el conjunto de datos mnist.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.488897Z",
     "start_time": "2020-11-25T01:04:18.001701Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from keras.layers import BatchNormalization                       \n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Sequential\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "np.random.seed(1)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color=\"cornflowerblue\">\n",
    "\n",
    "Parte I: **Análisis de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Importa y carga la base de datos mnist de Keras:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4>\n",
    "\n",
    "*El conjunto de datos mnist lo pueden obtener directamente de Keras: [mnist Keras](https://keras.io/examples/vision/mnist_convnet/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.493686Z",
     "start_time": "2020-11-25T01:04:19.490560Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    train_data, val_data, test_data = pickle.load(f, encoding=\"latin1\")\n",
    "    f.close()\n",
    "    return (train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "¿De qué tipo son los conjuntos que obtuviste?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of train_data:  <class 'tuple'> with length:  2\n",
      "The type of val_data:  <class 'tuple'> with length:  2\n",
      "The type of test_data:  <class 'tuple'> with length:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"The type of train_data: \", type(train_data), \"with length: \", len(train_data) )\n",
    "print(\"The type of val_data: \", type(val_data), \"with length: \", len(val_data) )\n",
    "print(\"The type of test_data: \", type(test_data), \"with length: \", len(test_data) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4 color=\"blue\">\n",
    "Tuplas con dos entradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "¿Qué dimensión tienen los conjuntos que obtuviste?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first element of the train_data tuple:  (50000, 784)\n",
      "Shape of the second element of the train_data tuple:  (50000,)\n",
      "Shape of the first element of the val_data tuple:  (10000, 784)\n",
      "Shape of the second element of the val_data tuple:  (10000,)\n",
      "Shape of the first element of the test_data tuple:  (10000, 784)\n",
      "Shape of the second element of the test_data tuple:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the first element of the train_data tuple: \", train_data[0].shape)\n",
    "print(\"Shape of the second element of the train_data tuple: \", train_data[1].shape)\n",
    "print(\"Shape of the first element of the val_data tuple: \", val_data[0].shape)\n",
    "print(\"Shape of the second element of the val_data tuple: \", val_data[1].shape)\n",
    "print(\"Shape of the first element of the test_data tuple: \", test_data[0].shape)\n",
    "print(\"Shape of the second element of the test_data tuple: \", test_data[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4 color=\"blue\">\n",
    "\n",
    "La primera entrada corresponde a los 784 razgos de las 50000 imágenes:\n",
    "\n",
    "$train\\_data[0][i][j] = $ el j-ésimo razgo de la i-ésima imágen.    \n",
    " \n",
    "La segunda a sus correspondientes etiquetas, una por cada una de las imágenes:\n",
    "\n",
    "$train\\_data[1][i] = $ la etiqueta de la i-ésima imágen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "¿Cómo se ve una muestra de entrenamiento?, Responde a esta pregunta mostrando un ejemplo, ¿qué representa cada valor en la muestra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features 150 to 199 of the 20th training sample \n",
      " \n",
      " [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.1484375\n",
      " 0.7421875  0.09765625 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05078125 0.09765625 0.0390625  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.4375     0.984375   0.48828125\n",
      " 0.015625   0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.515625\n",
      " 0.984375   0.44140625 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.23828125 0.984375   0.984375   0.140625   0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.515625   0.984375   0.9375\n",
      " 0.30859375 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.328125\n",
      " 0.984375   0.984375   0.140625   0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.515625   0.984375   0.984375   0.9296875  0.203125\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.046875   0.7734375  0.984375   0.984375\n",
      " 0.4765625  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.38671875\n",
      " 0.984375   0.984375   0.984375   0.70703125 0.06640625 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.19140625 0.984375   0.984375   0.984375   0.4765625  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.01171875 0.48828125 0.984375\n",
      " 0.984375   0.984375   0.390625   0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1015625  0.8515625\n",
      " 0.984375   0.984375  ]\n",
      "\n",
      " y value of the 20th training sample = 4\n"
     ]
    }
   ],
   "source": [
    "print(\"features 150 to 199 of the 20th training sample \\n \\n\", train_data[0][20][100:300])\n",
    "print(\"\\n y value of the 20th training sample =\",train_data[1][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4 color=\"blue\">\n",
    "Cada razgo representa una tonalidad de la imágen (en blanco y negro) normalizada a 1.\n",
    "Cada valor \"y\" representa el valor del dígito escrito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "¿Las muestras estan normalizadas?, (cómo puedes saber esto) si no estan normalizadas, normalizalas. \n",
    "\n",
    "*recuerda que en el caso de imágenes la normalizacion es dividir cada pixel por la intensidad máxima (255)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Máximo valor de los razgos = 0.99609375\n",
      "Mínimo valor de los razgos = 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Máximo valor de los razgos = \"+str(train_data[0].max()))\n",
    "print(\"Mínimo valor de los razgos = \"+str(train_data[0].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4 color=\"blue\">\n",
    "La muestra si está normalizada entre 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "\n",
    "En un ejercicio anterior se obtuvo la muestra en forma de arreglo, ahora muestra la imagen y su correspondiente etiqueta (usa un ejemplo del conjunto de entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is the digit corresponding to the sample 4321\n",
      "\n",
      " This is its image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 4321\n",
    "\n",
    "plt.imshow(train_data[0][index].reshape((28, 28)),cmap='binary')\n",
    "\n",
    "print(train_data[1][index], \"is the digit corresponding to the sample\", index)\n",
    "print(\"\\n This is its image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Dada una muestra de entrada (input) ¿de qué forma se indica la etiqueta (output)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "source": [
    "<font size = 4 color=\"blue\">\n",
    "Se representa con un número \"y\" que denota el valor del número escrito.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Convierte el output en representación one-hot.\n",
    "\n",
    "\n",
    "Hint: Puedes usar la función de Keras [to_categorical](https://keras.io/api/utils/python_utils/#to_categorical-function)\n",
    "\n",
    "Observa cómo cambian sus dimensiones (muéstralo usando shape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_data[0]   # input (features) in the training data set\n",
    "y_train = train_data[1]   # target (the digit) in the training data set\n",
    "\n",
    "x_val = val_data[0]   # input (features) in the validation data set\n",
    "y_val = val_data[1]   # target (the digit) in the validation data set\n",
    "\n",
    "x_test = test_data[0]     # input (features) in the testing data set\n",
    "y_test = test_data[1]     # target (the digit) in the testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.eye(10)[y_train]\n",
    "\n",
    "val_y = np.eye(10)[y_val]\n",
    "\n",
    "test_y = np.eye(10)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(train_y.shape)\n",
    "#Cambia de escalares a vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: Digit representation for the first training sample \n",
      " 5\n",
      "Y: One-hot representation for the first training sample \n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Y: Digit representation for the first training sample \\n\", y_train[0])\n",
    "print(\"Y: One-hot representation for the first training sample \\n\",train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Hasta aquí debes tener cuatro conjuntos de datos: los correspondientes a las entradas y las salidas de la red neuronal que se van a usar para el entrenamiento de la red (train_x y train_y) y los correspondientes a las entradas y salidas de la red neuronal que se van a usar para la prueba (test_x, test_y).\n",
    "\n",
    "Muestra las dimensiones de estos cuatro conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiamos el shape de las imágenes, y especificamos que solo hay un canal (blanco y negro). A queras no le gusta que no lo especifiquemos\n",
    "train_x = x_train.reshape(50000, 28, 28, 1)\n",
    "val_x  = x_val.reshape(10000, 28, 28, 1)\n",
    "test_x = x_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1)\n",
      "(50000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color=\"cornflowerblue\">\n",
    "\n",
    "Parte II: **Implemetación de la red neuronal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Implementa una red neuronal de convolución dentro de una función (como lo hemos visto en clase). Puedes guiarte con el notebook de la clase 10 o de [mnist Keras](https://keras.io/examples/vision/mnist_convnet/) *(no uses la misma arquitectura que se da)*.\n",
    "\n",
    "Cuida que la función que implementes sea flexible, es decir, que si cambiamos las dimensiones de las entradas no se tenga que modificar la función directamente, más bien indicarlo como un argumento de la función. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(_Conv)\n",
      " |  Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers, does not include the batch axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      filters: Integer, the dimensionality of the output space\n",
      " |          (i.e. the number of output filters in the convolution).\n",
      " |      kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
      " |          height and width of the 2D convolution window.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |      strides: An integer or tuple/list of 2 integers,\n",
      " |          specifying the strides of the convolution\n",
      " |          along the height and width.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Specifying any stride value != 1 is incompatible with specifying\n",
      " |          any `dilation_rate` value != 1.\n",
      " |      padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |          Note that `\"same\"` is slightly inconsistent across backends with\n",
      " |          `strides` != 1, as described\n",
      " |          [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n",
      " |      data_format: A string,\n",
      " |          one of `\"channels_last\"` or `\"channels_first\"`.\n",
      " |          The ordering of the dimensions in the inputs.\n",
      " |          `\"channels_last\"` corresponds to inputs with shape\n",
      " |          `(batch, height, width, channels)` while `\"channels_first\"`\n",
      " |          corresponds to inputs with shape\n",
      " |          `(batch, channels, height, width)`.\n",
      " |          It defaults to the `image_data_format` value found in your\n",
      " |          Keras config file at `~/.keras/keras.json`.\n",
      " |          If you never set it, then it will be \"channels_last\".\n",
      " |      dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
      " |          the dilation rate to use for dilated convolution.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Currently, specifying any `dilation_rate` value != 1 is\n",
      " |          incompatible with specifying any stride value != 1.\n",
      " |      activation: Activation function to use\n",
      " |          (see [activations](../activations.md)).\n",
      " |          If you don't specify anything, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |      kernel_initializer: Initializer for the `kernel` weights matrix\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      bias_initializer: Initializer for the bias vector\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      kernel_regularizer: Regularizer function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      bias_regularizer: Regularizer function applied to the bias vector\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      activity_regularizer: Regularizer function applied to\n",
      " |          the output of the layer (its \"activation\").\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      kernel_constraint: Constraint function applied to the kernel matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      bias_constraint: Constraint function applied to the bias vector\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |  \n",
      " |  # Input shape\n",
      " |      4D tensor with shape:\n",
      " |      `(batch, channels, rows, cols)`\n",
      " |      if `data_format` is `\"channels_first\"`\n",
      " |      or 4D tensor with shape:\n",
      " |      `(batch, rows, cols, channels)`\n",
      " |      if `data_format` is `\"channels_last\"`.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      4D tensor with shape:\n",
      " |      `(batch, filters, new_rows, new_cols)`\n",
      " |      if `data_format` is `\"channels_first\"`\n",
      " |      or 4D tensor with shape:\n",
      " |      `(batch, new_rows, new_cols, filters)`\n",
      " |      if `data_format` is `\"channels_last\"`.\n",
      " |      `rows` and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      _Conv\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An output shape tuple.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_metric(self, value, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          value: Metric tensor.\n",
      " |          name: String metric name.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Conv2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MaxPooling2D in module keras.layers.pooling:\n",
      "\n",
      "class MaxPooling2D(_Pooling2D)\n",
      " |  MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)\n",
      " |  \n",
      " |  Max pooling operation for spatial data.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      pool_size: integer or tuple of 2 integers,\n",
      " |          factors by which to downscale (vertical, horizontal).\n",
      " |          (2, 2) will halve the input in both spatial dimension.\n",
      " |          If only one integer is specified, the same window length\n",
      " |          will be used for both dimensions.\n",
      " |      strides: Integer, tuple of 2 integers, or None.\n",
      " |          Strides values.\n",
      " |          If None, it will default to `pool_size`.\n",
      " |      padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |      data_format: A string,\n",
      " |          one of `channels_last` (default) or `channels_first`.\n",
      " |          The ordering of the dimensions in the inputs.\n",
      " |          `channels_last` corresponds to inputs with shape\n",
      " |          `(batch, height, width, channels)` while `channels_first`\n",
      " |          corresponds to inputs with shape\n",
      " |          `(batch, channels, height, width)`.\n",
      " |          It defaults to the `image_data_format` value found in your\n",
      " |          Keras config file at `~/.keras/keras.json`.\n",
      " |          If you never set it, then it will be \"channels_last\".\n",
      " |  \n",
      " |  # Input shape\n",
      " |      - If `data_format='channels_last'`:\n",
      " |          4D tensor with shape:\n",
      " |          `(batch_size, rows, cols, channels)`\n",
      " |      - If `data_format='channels_first'`:\n",
      " |          4D tensor with shape:\n",
      " |          `(batch_size, channels, rows, cols)`\n",
      " |  \n",
      " |  # Output shape\n",
      " |      - If `data_format='channels_last'`:\n",
      " |          4D tensor with shape:\n",
      " |          `(batch_size, pooled_rows, pooled_cols, channels)`\n",
      " |      - If `data_format='channels_first'`:\n",
      " |          4D tensor with shape:\n",
      " |          `(batch_size, channels, pooled_rows, pooled_cols)`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MaxPooling2D\n",
      " |      _Pooling2D\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _Pooling2D:\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An output shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_metric(self, value, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          value: Metric tensor.\n",
      " |          name: String metric name.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MaxPooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [],
   "source": [
    "def architecture(input_shape, num_classes, activation, dropout=False, batch_normalization=False):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #Padding=valid es p=0 (aplicable, ya que los números están centrados) Hace que la dim de salida sea (n-f+1)/s\n",
    "    model.add(Conv2D(filters = 28, kernel_size = 3, strides = 1, padding='valid', input_shape=input_shape)) #(28-3+1)/1 = 26\n",
    "    model.add(Activation(activation))    \n",
    "    if batch_normalization: \n",
    "        model.add(BatchNormalization())  # Performing batch normalization to the output of the input layer\n",
    "       \n",
    "    #Aqui si le agregamos padding tal que la dim de entrada sea la de salida\n",
    "    model.add(Conv2D(filters = 15, kernel_size = 5, strides = 3, padding='same',kernel_initializer='he_uniform',bias_initializer='zeros')) #26\n",
    "    model.add(Activation(activation))    \n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())  # Performing batch normalization to the convolution layer\n",
    "        \n",
    "    #model.add(MaxPooling2D())\n",
    "    model.add(AveragePooling2D()) #Filtros de 2x2 (reduce por la mitad a 13)\n",
    "    \n",
    "    model.add(Conv2D(filters = 20, kernel_size = 2, padding = 'same', kernel_initializer = 'he_uniform',bias_initializer='zeros')) #13\n",
    "    model.add(Activation(activation))    \n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())  # Performing batch normalization to the convolution layer\n",
    "               \n",
    "    model.add(Conv2D(filters = 20, kernel_size = 2, padding = 'same', kernel_initializer = 'he_uniform',bias_initializer='zeros')) #13\n",
    "    model.add(Activation(activation))    \n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())  # Performing batch normalization to the convolution layer\n",
    "    \n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Flatten()) #13x13x20 = 3380\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.20))\n",
    "    \n",
    "    model.add(Dense(40, kernel_initializer='he_uniform',bias_initializer='zeros'))\n",
    "    model.add(Activation(activation))    \n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())  \n",
    "    if dropout:\n",
    "        model.add(Dropout(0.30))\n",
    "    \n",
    "    model.add(Dense(25, kernel_initializer='he_uniform',bias_initializer='zeros'))\n",
    "    model.add(Activation(activation))    \n",
    "    if batch_normalization:\n",
    "        model.add(BatchNormalization())      \n",
    "    if dropout:\n",
    "        model.add(Dropout(0.10))\n",
    "    \n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax',name='CNN_Cifar10Model'))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Crea el modelo definido en el ejercicio anterior (es decir llama a la función que creaste con los argumentos adecuados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [],
   "source": [
    "one_image = (28,28,1)\n",
    "activation='sigmoid'\n",
    "num_classes=10\n",
    "dropout=True\n",
    "batch_normalization=True\n",
    "\n",
    "mnist_model = architecture(one_image,num_classes,activation,dropout,batch_normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Usa la función plot_model para obtener una representación esquemática del modelo implementado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAEJMAAAA8CAYAAADMWUzlAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3dfZAU5Z3A8d/sLmgsDHrAAnqAopgYODHhOMnpEYPGRL1Zqy6Sgt3yLi9qLaWeyUHVGZzN6WlJlS5RjzohLGcsqN3ZAj1yu1FTSVhzxLigwSzGNzZEa1cSs4svu3Jy+AK/+4N7hp7e7pnunu6dnt7vp2qr2J55+nmmn5ffr3t6m5SqqgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAJbq4qdwsAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQHh4mAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAkCA8TAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACBBeJgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAgtTYN/zpT3+S73znO3L06NFytAdFXHfddZJOp8vdjEA6Oztly5Yt5W5G4px77rlyzz33lLsZgbDexAvrCxAd5hfsiN8IC+sLEB3mF1C66upquf/++2XatGnlbkogq1evlv3795e7GYnD+oowsL4A0WF+wQnxG2FgfQGiw/xCUvF9WrLRv7AjniUb/YuwED+A6DC/YEf8Tjb6F2EhfgDRYX7BjvidbPQvwuIWP6rsG7q6uqS9vX1UGgV/tm3bVtF9097eLtu2bSt3MxJl27ZtsmbNmnI3IzDWm/hgfQGiw/yCHfEbYWF9AaLD/ALC0d7eLl1dXeVuRmBr1qxhLoWM9RVhYX0BosP8gh3xG2FhfQGiw/xCEvF9WrLRv3BCPEs2+hdhIH4A0WF+wQnxO9noX4SB+AFEh/kFJ8TvZKN/EYZC8aPGrdDWrVsjaxCCaWhoKHcTSlZfXy+tra3lbkZitLW1JWJcsN6UXxLGEesL4or5BTviN8KShHHE+oK4Yn4B4UilUuVuQslaW1ulvr6+3M1IDNZXhIX1BYgO8wt2xG+EhfUFiA7zC0nE92nJRv/CCfEs2ehfhIH4AUSH+QUnxO9ko38RBuIHEB3mF5wQv5ON/kUYCsWPqlFuCwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACLEwyQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAShIdJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJAgPkwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEgQHiYBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACQIDxMAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIEF4mAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAECC8DAJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACABOFhEgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAnCwyQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAShIdJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJAgPkwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEgQHiYBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACQIDxMAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIEF4mAQAuGhqapKmpqbE1IP4GRwclPb2dqmrqyt3U0aF0+cdjfHPHAPGFuI3okb8Jn4DpSrXvAKQfOTCiBJ5MHkwgGgQvxEl4jfxG8nDdSWIjL31HQBQGOeViNpYyz04twQAlIr8DFEjPyM/AwD4Q352XMkPk0ilUo4/5TA8PJxXd5zahtLt2rVLmpqacv3Y1NQke/fulcHBwbL2a39/v6xYsUJSqZSsWLFCurq68l53G4epVErWrl0rnZ2dMjw8XKbWJ4M5/qWwrx9RGa16UFixednS0uJ7n0H69l/+5V9k+fLl0tnZ6fh6V1dX3prn9bPEVbHPGwbmWPwQv+GG+A2/iN/lQfwe28JYq+PKbT2pq6uTlpYWGRwcjKzu0ZhXBjlP+ZAHoxByYfhBHlwe5MFjE/EbhRC/4QfxuzyI32ODfTzu2rXL9b27du2KZPxyXek4cpBwFTqe9jEcZBw4rV+saaNnLM0XxpU/Y2lsgPNK+Me5ZXlwbjk2jKUYzHjzZyyNDZCfwT/ys/IgPxsbxlIMZrz5M5bGBsjPIqc2ra2t6rC5oKGhIRURFREdGhryVTZMHR0dI9o+MDAQi7aFob6+Xuvr68vdDFVV3blzp7733nu+ypTS/kwmo42Njbpv377ctoGBgVyf+x2zYRkaGtKOjo7cv7PZrIpIbpvhNg57eno0nU5rOp3WgYEB3/UHma9ReeWVV/T3v/+9rzJhtL+vry93bHt6egLvx2n9iMJo1eNXnNaXp59+2vd6HaT91nlptWPHDhURzWazvvYXtG+LrWHWtSWTyTi+x3yWIOvIaIt6zY7jHIvT/CJ+H0f8PoH4Ha96/IrT+kL8zkf89ieOcywu8+vYsWP6i1/8Qt9//31f5cJof1hrdZw5rSl9fX2ayWRURPJymLCNRi5U7pxH9fjnbG1tDf4hQtLf368vvPCC73JB208e7C4u66vq6J8fGeTC4YjL+jI0NKTd3d368ccf+yrnt/3kweUxFvNg1fjMr3feeUd3796tR48e9VWO+E38tiN+x0dc1hfidz7itz/Mr8I++OAD3blzpx45csRXOb/tt67LjY2Nru9rbGzMvS/s8ct1peOizEHi9H3aiy++qH19fb7KlHr/nZ2JH4bfceC0fpVzTYtT/7722mv6yiuv+CoTpP1Rzpc4KWVcxSWeHTlyRHfu3Kkffvihr3JB2z9WxkZc+vfQoUP6q1/9KvLzATvOK8MRp/jR29urvb29vsqUGj+sOLeM1lg8t4zT/HrllVf0tdde81WG/Mwd+Rn5mZu49C/5Wbzq8StO8YP8LB/5mT9xnGNxml/kZ+EiPyM/cxOX/iU/i1c9fhVYf2+qkhBMnDjR8d+jaXh42PEpXrW1tbl/l6ttSdPb2yuLFy+WT37yk3LttdfKj370I/nggw8iq8/8z0/r16+X8847L7e9trZW0um0dHd3R1Z3MTt37pR0Oi0ix8fXsmXLRESkrq4u731u43D+/PmyadMmERG5/vrrK/pJSOeff76cc845smDBAnnwwQflT3/606jUu23bNuno6BARkWeffTbQPtzWj7CNVj2V7Pe//71ccsklctppp8k111wjjz32mPzv//5vJHVZ56XVkiVLRESkra3N876i7Fvr2nL33XdLe3v7iPeYz+L2mcYK5lhh1vj9ta99jfhN/BYR4nec6qlkxO+RiN/eMccK+/Wvfy2XXnqpTJgwQZYvXy6PP/64fPTRR6NSdxhrddw5zb+ZM2fKLbfcIiIi999//2g3KVTkPCcsX75cLrjgApkzZ47cfffdsn///sjqIg+uDPbrm9u3b4/0/MiKXDhZHn74Yfn85z8v06ZNk29/+9uye/fuSOohD04e5ldx999/v1x00UVyxhlnyKpVq+T555+PrC7id2UgfsernkpG/M5H/PaO+VXcj3/8Y1m8eLFMmTJFrr/+ennqqafk2LFjodczc+ZMERFpbm6WDRs2SH9//4j39Pf3y7nnnpv7Pezxy3Wl48ZCDiIiMm/ePJk1a5YsWrRIHnroITl48GAk9RS6r83EjyCc1i/WtBO+8IUvyPnnny/z5s2T++67z3FNCcNYmC9JGVcmnk2ePFluvPFG+cUvfhFJPDPGwtiIk4cfflguvvhiqa2tlX/8x3+UZ555RlQ18no5r0yev/iLv5DzzjtPPvvZz8r3v/99+cMf/hBJPZxbJg9zrLjzzz9fZs+eLX/5l38p//Zv/xbZ/WxjIQYnZbyRnyUb+Vl86ql05Gf5yM+8Y44VR34WnqSMN/KzZCM/i089YQvlYRJOBgcHpb29PfdFYmdnp6RSKamrq8t96TI4OCidnZ2597S0tEgqlZIVK1ZIb29vbl+pVCr347atublZOjs7817zy3SiKd/U1CSDg4Oydu3avPrWrl2bK2N9zfq5zPa6ujrp6uoa8XmHh4dlxYoV0tTU5Lud5Wa9Meu//uu/5O/+7u9k8uTJ8s1vflN+/vOfy9GjR0Ora9euXXL33XfL6tWrXd+zaNGiEduGh4elvb091zctLS0yODiYe73Y+Ny1a1den1vHk7XP58+f79imxsZGz5+xtrZWvv3tb0tnZ6fs3LnTc7m4Oeecc0RE5De/+Y2sWrVKzjzzTPniF78oDz/8cGTBeHh4WIaGhnI3Mdx4440F32sfE4bT+mEdI17HQ39/v+s64qWeYu31M4Yr1eHDh3P/fuKJJ2Tp0qUyefJk+fu//3v5yU9+Eur6UozpK8Nv31rLuY09pzpNHLT2t9Hc3CzLly93PJl34mUcOcUlt/G1YsWK3Pgy+7VuK3ac7JzGv32umR/zHuZYcNb4vX379rz43dXVRfwW4jfxm7UlKOI38Zv4HR0Tv1VVHnvsMfnbv/1bmTx5sqxYsUJ27twZ2cXXYmu1nzVWJNh1Ei/jsqurS+rq6nLXapzGrVvdhZgLzxs2bBhxXAqNQb/vs7bROnb9jOVCx8D0n91YzHnMFwj79++Xf/3Xf5U5c+bI5z73OXnwwQflzTffDK0e8uDKYb+++dWvfjWy65tW5MLJitMiJ8bSW2+9JevXr5dFixbJrFmzpKmpSV5++eVRawd5MHlwEueXeYjawMCArFu3ThYsWCCzZ8+WO++8M+87xFIRvysH8Zv4HRbiN/Gb+B2dI0eOiIjIoUOHZPPmzbJkyRKZNm2arFy5Up577rnQ67v88stFROSZZ54Z8dozzzyTe92uUD87rcVu67MTriudkJQcRERk0qRJIiLy3HPPya233irTp0+XL3/5y7JlyxY5dOhQ5PWbcVfoZk2/61eh2FLoem4S1y4zb19++WVZvXq1nHXWWfL5z39e1q9fL2+99daotcE+X4rdZ+gnDou435fpdX9O66B9Wxj3b8aByRffe+89eeSRR+SLX/yiTJ8+XVatWiV79uwZ1bYUWkvDmKumvOlve58F+Y4l7sx32++884784Ac/kIsvvlhmzJght99+u7z44ouR1Ml5ZfJih4jIn//5n4uIyN69e+Wf//mfZcaMGfI3f/M3smnTJnnnnXdGrR2cW3JumcQ5NmXKFBERef7552XlypVy5plnymWXXSY//OEPR+2Pw8jP4oX8rHgdlYz8jPwsLORn5GfkZ9EhP/O2P/Iz8jPys+DIz0YpdqhNa2urOmwuSkTyyqXT6dy27u5uVVXt6+tTEdHGxsa8Mtb3DA0NaWNjo4qI7tu3T1VVBwYGRuzf7Mu6zf57se12pt6BgYERbe3u7s773SqdTuvAwECurel0WrPZrKqq7tixQ0VEe3p6RhyTnp4ex/25qa+v1/r6es/vj8oLL7yQ13fmZ9y4cSoiOnnyZL311lt1165deeWCtD+TyeT6xI90Oq0bN25U1RN9kk6ndWhoKPd6sfFp+i6TyTi2q6enZ8T2oaEhFRHt6OgY8VqhcWjK+RkPqsHnaxTmzJkzYkxUV1drdXW1jhs3Tuvq6nTr1q16+PDhXJlS25/NZnP9sHHjxtxcc5JOp/P6srGxMe/3QmuYqvfxUGgd8VKPdXupY9iPSllfTj/9dL3pppv06aef1mPHjuXKBW1/obhh1nHDb98aXsee6cd9+/Y59qPZt1kX7WPdrW4/48jEJet2U481DhYac36Ok9P4t6/5HR0dKiLa19cXqB/iMMcqZX6Z+L179+68csRv4jfxO55ri2rlrC/Eb+J3Jc6xuMyvX/7yl47za/z48SoiOm3aNF21apU+//zzeeVKbb+XtdrrGhv0OkmxcWPGmenrbDabd4yK1W04jTW3GF9sDPp5X6F55XUsezkGTp9rtHIes9/W1lbf5cJ29dVXj5hHqVRKa2pqtKqqShcvXqybNm3Sd999N6+c3/aTBxcXl/W1WP4yadKk0K5vWpELh5cLx2V9WbNmTW7cOI2lz3zmM3rvvffm8iIjSPvJg8mDvR4bt8/rVVzm12233VZwfl144YW6du1aPXDgQF454jfxm/jN+lIM8Zv4TfyOjvn+wP5jrmXNmjVLv/e97+mrr76aVy7o/FI90Wd29vuS7K8V6mez3tvvA3KaF/Z9c13JuVyQcR2n79OmTp06YlxXV1drVVWVjh8/Xq+99lrdvn27HjlyJFcmrPvvTP8Ve1+QOOK0zc/1XGv7Kvn70oULF47o36qqqtx3pldccYVu3rxZDx06lCsTVv9a2edLsfsMi60X1s9T6L5Mr/sr9f5Nr8cnLvGspqbGNZ6dddZZescdd4w4hqW03+9aGsZcbW5uzuVAQ0NDuTzQSx1BP2Mc+nfNmjV60kknjehfcz7w6U9/Wu+55x59/fXX88qV0n7OK8PLe+MUP5zutzHxo6amRq+66ipta2vT999/P1cm7Pghwrml2c65ZbLys+nTp7vm3+Z+tkcffTSU+9nIz4ofnzjEb/Kz4nUE/Yxx6F/yM/KzsJCfkZ+Rn0WH/Mzb/sjPyM/Iz8jPyh07VAuuvzeN2BrmYu1lm9N7enp6VES0ubm55H0V2m6XyWQKdmhzc3NeMmHaak32zBes9vrN4DL7tH8h7EXcb9ZyWvxnzJihmUxGX3rppUDtDxIgzYS2JoImAbX2lZcxZRZ5a3+Zxd+tbqcv/L18liCfNU7JodPJl/WnpqZGU6mUfuITn9DrrrtOn3zySd28eXPg9psEzTDrhllcrcy8tI+JdDqd+z2s8VBsHfFST5hj2KtKXF/OOOMM/e53v6t79+4t+Y9R7T+ZTGbEPA7St2GNPbNN9fiYM4mCNbG2v9/vOLJ/3qBx3e9xKjRmzUWNHTt2BN6/07bRnmOVOL9mzpxJ/Pb4WYjf/hC/id/Eb+K31/2Ve47FZX65PUzCaX7Nnj1b77zzTu3t7S2p/X7Wai9rbNDrJEHHjfVaUrG6rfsxF/+sF3zNRTlV72Mw6FgNMi+8HAOr0c55TLk4XNx2epiE9cd8eTxu3DhNp9Pa3t6uhw8f9t3+IMdpLOXBqvFZX/1e37z99tsDnx8Z5MLh5sJxWV/c/hjV/JgH16RSKV20aJE+9NBDevDgwUDtd6uDPJg82M8x8CIu88vtYRJO8+uSSy7RlpYWffvtt4nfxG/it8d6xvL6QvwmfhvE7/C5PUzC+mPm37x58/S+++7TN954I/D8Uj1xvK3XcXp6enL96nRMi/Wzav4NYs3NzY4PnjLluK4UTQ4Sp+/TnB4mYf0xcWPChAn6jW98Q3fs2KFbtmwJPJ+dftzeZ4Sxfql6v55bbD/FxKl/nR4mYf2xPjhk6dKlun37dn3kkUdK6l+vr7vF0VJijdN9mWHGrqBz3pSNSzxzuhneKZ5dcMEF2tzcrAcOHCip/X7HRhhz1d7n5g8evNbhV1z61+1meHv/plIpXbhwoa5bty53bIK0n/PKcPPeOMWPYvfbmPhx8skn67Jly7SzszPw/TZudXBuybmln2NQTJzml9MfK1p/TP59yimn5O5nKzX/9vq621gkP4sW+Zm3OvyKS/+Sn514T6XFDtV4xQ/yM/Izg/wsfORn5Gd25Gfe6vArLv1LfnbiPZUWO1QLP0wi9f87zmlra5OGhgaxbS4qlUqJHK/F1zan93h9X9B9FdPf3y/btm2TVatW5ZXbu3evXHjhhbJx40a54YYbRERk7dq1snTpUpk5c6aIiNTV1UlnZ6fjflXVd1usGhoa5OWXX5Y5c+b4Lhum4eFh+elPf+r5/ePGjZOPPvpIRESuvPJKeeKJJzyXDXK8VqxYIRs2bMgrMzw8LKeddpqk02np6Ohw3bd9m+nzbDYry5YtExGRrq4umTRpksyfP39E3XV1dbJ69WpZtGiR788S5LOa+bp06VLPZaKyY8cOeeeddzy91zomRILNh66uLhERWbJkSW5bKpXK62PDzMtC9YQ9HtzWES/1hDmGvWpoaJB9+/bJ7NmzfZULWynry5e//GX5yU9+4qs+p+M1ODgo69atk71798qmTZuktrY2r4yfvg1r7Jlt5vfBwUGZOnWqpNPpXButr4uUNo78tsupvNfj5FZ+cHBQrr/+evnCF74gK1eutB+2ippjSYjfV111lTz++OOeyxK/CyN+E7+L7csr4jfxm/gdbfx+8803ZfLkyZ7LROGtt96Sp556yvP7a2pq5OOPPxYRcVxbvfCzVntZY0u9TuI2bpzGhH1fxeq2lrHKZDJy7bXX5sUJr2Mw6FgNch3MyzGwGu2cx5S76KKLctfNyqW7u1sOHDjg6b3WeSQi0traKvX19Z7KkgcX19DQIC+88IKcf/75vsqFbTSvbxrkwuHmwnFZX1599VV59dVX886V3FRVVcmxY8dyvz/yyCPyD//wD57rIg8mD/Z7bCp9fv3xj3+UZ599NtD82rx5s1x33XWe6iF+F0f8Jn4X25dXcVlfiN/Eb/MZid/h6+/vl927d3t6byqVkqqqKjl69KiIiKxfv14aGxs912Udk6lUShobG2X9+vUiItLU1CR33XVX7jUR52Pq1s8i+fOgublZzjvvPMc22HFdaaSg4zpO36c98cQT8v7773t6b6nfp9mPV39/v8yaNcvTOmreH3T9Egl2PbfSvy/ds2ePvPbaa57eG3b/Fnvd7f1hx+EwY1fQOW/KxiWe7dmzJ+86sRt7PPvBD34gN954o+86/Y6NMOaq6fdsNitXXnmlTJw4MW8/Xr5j8SMu/fvGG2/Ib37zG/nggw+Kvtd+zH74wx/K17/+dV/1cV4Zbt4bp/jx85//XN59911P740ifnBu6b9dTuU5tzyB+UV+5vb54xC/yc/EUx1+xaV/yc/Iz8JS7vhBfua/XU7lyc9OYH6Rn7l9/jjEb/Iz8VSHX3HpX/KzZORnDuVurvK1pzGgpaVFbr75Zkmn0yNemz9/vjQ2NsqNN94ow8PDMjw8LPv378+boGYBUNURPxCprq729X5zs8Dw8LDnMhs2bBixzSzWbgu0m/nz50s6nZa2trbctqeeesrxBr729nZJp9OOX54XYz5fJpPxXXaseuCBB+Syyy6TVCqV+xE53se9vb157/Xb7268jodC64gXYY7hsaSqKpyQVltbK7fccot0dnbKunXr8l7z27dR9Vdtba309PRIZ2enXH/99Y5rZDnHUalzQERyx97pJJ45Nvr8zi/iN9wQv2FH/M5H/HbHHPMv6Pzys1Z7WWNLuU5SaNyYfKO9vV1Ejl/YExFpbm4OVLf1tbvuumtEnPA6BkdzrHo5BgY5z+ggDx4b/F7fNMiFYef0h2d+kQeXjjw4mfzML+L32ED8Hon1JRji9wnEb3fMr2CCrtUiItlsVjZs2CD9/f0yODgoc+fOLVqmWD/X1tZKNpuVzs7Oog/l5rqSu7Geg4TBz02jYayP3PdWPn7mS9jrBbErPGF992nlNDbCmKvf+c53JJ1Oy/Lly+W0006TtWvX5r3OehAOzisRFc4tS8e5JYohP0sG8jPYkZ8hKuRnpSM/QzHkZ8lAfgY78rNRpDatra3qsLkoERlRzss2p/eY7Y2NjaHtq9BnMvVks1kVEe3r63Mt19PToyKi2WxWOzo6tLu727Guffv2OdZVrC2F1NfXa319faCyYXrhhRdyn8PtZ/z48SoiOmPGDM1kMvrSSy8Fan9HR4eKiPb09Hguk06nVUR0YGAgb3uQMaV6Ylx0d3drX1+fdnR0jKizp6dHM5lMwXYV6vsdO3aoiOiOHTsK7sMu6HyNwpw5cwqOiZqaGk2lUvqJT3xCr7vuOn3yySd18+bNgdrf3d2t2Wx2xHbr/LQyY6LQOAprPBRbR7zUE/YY9qIS15czzjhDv/vd7+revXsDt7/Q8bK/FqRvwxx7Tu00a2Qmk3GtO8g48tuuUo6T0z43btyYtw+rSpxjlTi/Zs6cSfwusG+D+O0P8dtfm72oxPWF+E389rq/cs+xuMyvX/7yl57n1+zZs/XOO+/U3t7ewO33u1arFl9jTTv9Xifxco2mo6NDm5ubVUQ0nU6PaF+xugvVb+d1DAYdq0HmhWrxY6BavpzH7Le1tdV3ubBdffXVBedRVVWVVldX67hx4zSdTmt7e7sePnzYd/vJg4uLy/rq9/rm7bffHvj8SJVc2G+bvYjL+rJmzRodN26c6zhKpVK586pFixbpQw89pAcPHgzU/kLHqtT8TpU82Ol1L8ctaXmwKReH+XXbbbd5nl+XXHKJtrS06Ntvv038Jn4Tvz3WM5bXF+I38Zv4HR3z/UehHzP/5s2bp/fdd5++8cYbgeeX0dfXl1ubs9lsXt8WWmcLXXcaGBjQ5ubm3HUXe3+6lXPCdaVgOUicvk+bOnVqwXFt4saECRP0G9/4hu7YsUO3bNkSeD57KRdGHCm0zc/13CBrV5z6d+HChQX7t7q6WquqqnT8+PG6dOlS3b59uz7yyCOh96/TfHF7fxhxOIz1x2lb0FhmysYlntXU1HiKZxdccIE2NzfrgQMHSmp/0LERxlzt6enRxsZGFRFtbm72XIdfcenfNWvW6EknnVS0f1OplC5cuFDXrVunAwMDgdrPeaW/NnsRp/hR7H4bEz9OPvlkXbZsmXZ2dga+36bQ8QojJ+DcknNL1XjNr+nTpxecXyb/PuWUU3L3s0WRf5OfxSd+k595q8OvuPQv+Vn+65UUO1TjFT/Iz8jPyM+iQ35GfmZHfuatDr/i0r/kZ/mvV1LsUC0YP24asTUOD5PYt2+fikheB5SymBY6cNYB53V/ZvKn0+kRr5nkI5PJ6NDQkKqe+JK5WFuKifvNWmaRnzx5st566626a9euvHJB259Op/Mmh11fX1/eQmydyMbQ0JCnhMFpm1nMGhsbNZvN5vrV+rq1ftUTQaLYvk35dDrtOJ6KiVNy6HTyVV1dnftjjLq6Ot26dasePnw4VyZo+xsbG0f0g+F0LM28tJbr6+sLtOgWGw/F1hEv9YQ9hr2olPXl9NNP15tuukmffrp4ibYAAA/7SURBVPppPXbsWK5c2H+Mam44KvWmnDDHnlu/mvFSKKkxvI4jv+3yc1yK/d7d3T2ijaXU57RttOdYpcwvE793796dV474TfwmfsdzbVGtnPWF+D0S8Tv+cywu88vtYRLmD6SmTZumq1at0ueffz6vXND2+12rVYuvsUGvkxQbJx0dHa5t9Vp3ofrtvI7BoGM1yLzwcgzKmfOY/cbh4rbTwyTMH4hVVVXp4sWLddOmTfruu+/mlQvSfvLgwuKyvhbLXyZNmhTq9U1yYX9t9iIu64vbH6OabZ/5zGf03nvvHXGzQpD2ux0r8mDyYD/HwIu4zC+3h0mYbRdeeKGuXbtWDxw4kFeO+E38Jn6zvhRD/CZ+E7+j4/YwCXMta9asWfq9731PX3311bxyQeeXlbnx2R4zg4wrVc3tZ2hoyDVX8NpfXFcKloPE6fs0p4dJWB8wcO211+r27dv1yJEjuTJh3n/n5X1hjAvVYNdzg6xdcepfp4dJmIfPVldX6xVXXKGbN2/WQ4cO5cqE3b9u88Xt/aXEGqf7MsOMXUFjmSkbl3jmdDO8iWdnnXWW3nHHHSNuEi+l/X7HRhhzVUTyYoG5QdtrHUE+Yxz61+1meHM+8OlPf1rvueceff311/PKBWk/55X+2uxFnOKH0/02Jn7U1NToVVddpW1tbfr+++/nyoQdPzi35NzSzzEoJk7zy+mPFU3+be5ne/TRR0O5n438rLC4xG/yM291BPmMcehf8jPnMpUQO1TjFT/Iz8jPyM+iQ35GfmZHfuatjiCfMQ79S37mXKYSYofqKDxMwnwA6wQxB9O6zfo+8zQN87t5oMPQ0JBmMpkRHW0e4GAWERPorYmW9UkdZtJZ22Fn9mGeRGLK9/X15RZ+a1vt5TZu3Dhin9b6rD99fX0F2+JFHG/Wsj9d/2c/+5l+/PHHjuWCtt8s6o2NjSOCSF9fn6bT6bw+Ml/mW7dns9m8RcHr+DTcbjwwbXPqc2vS4DRHVI8HEXtb/YhTcnjOOeeoSP4fY1x66aX6H//xH66LepD2Z7PZgv/zhekr65OHnPrJPp7s64d1jHgdD9b9uK0jXuqJYgwXE+f1xfp0ujDXF6djqHo88Td97DRGvPatqaPQ2HPrf/s28z63fnV6KqTfcVTs2Di11WlboeNkf7/9d3MBxWmtNW2sxDkW5/ll/d9xiN/Eb+J3Za0tqvFeX4jfxG/idzisD5MwF+E++clPamNjo/73f/+3Hj161LFckPYHWavtrzmtsUGvkxQbN077NPPVabzb61b1Nz68jEGv7ys2r/xeU3M7BuXOeUwb43Bx+6qrrhoxlz772c/qAw88oH/84x9dywVpP3lwYXFZX0fz+ia58InPFFacVo3P+rJmzZrcZzBfiM6cOVMzmYy+9NJLruX8tp88mDx4LM6v2267bcT8Ovvssx1vOLAifhO/7YjfrC92xG/iN/E7OtaHSZjz7ylTpug//dM/6bPPPutaLuj8sh4ncwOf9X8icltnC/WzuWfJOm9N31hjA9eVRh6HsHOQOH2fNmnSJBU5/gcINTU1eQ8YeO+99xzLhHX/nRO/66P1dWscKXafnfXHfj231LUrTv27YMECFTnxfWkqldJFixbpQw89pAcPHnQsE2b/us0Xtzhq9uVlXTHli92X6XV/Qe/f9CrO8ay2tlZXrlypv/71r13LBW1/kLU0jLlqYpv5zsT+IMVCdQQRl/51Oh8488wzdfXq1frb3/7WtZzf9nNeeeIzhZn3xil+2O+3SaVSeskll2hLS4u+/fbbjmWCtJ9zS84tR2uOxWl+TZkyJW9+VVVV6ZIlS/Thhx8O9X428rPi4hK/yc+K1xFEXPqX/Cx/P5UUO1TjFT/Iz8jPyM+iQ35GfmZHfla8jiDi0r/kZ/n7qaTYoRrxwyScBrzTj9N7rdvM5BU5/pAGezAxN2uJnPhiMp1OazabzR0Q8+VwJpNxnYxOP6Yue/lMJqONjY2OEzidTrverNbX15cbSNby1jrtQcWLuNysZR38X/3qV0c8Xd9NKe0fGhrSjo6OXFA1x3Djxo2O/TMwMJB70oxZNKxjyuv4NMzYsPe5tT32H/PeQmOvubk578kyfsUpOTSf6XOf+5w+8MAD+uabbxYtU+p64/Q/Arm9x8xpM8ftfVls/XB6r9MaUGwd8VpP2GO4mLisL/v378+13+npdG78tr/QvHRbW/z2rVFo7HnpR7eYaucUV/yMI2t5vzHcuq3QcSr2udxuSPK6f6fX4zDH4jK/rPF76dKlxG+XcUb8Jn5XytqiGp/1hfhN/C72uStxjsVlfj377LMqcvwi/LJly/THP/6xfvjhh0XLlTq//KzVqoXXWNVg10m8jBu38We9yOalbq9jpNgY9Po+L2uG17lb6BiUO+cx+4/Dxe2LL75YRUTPPfdcveuuu/R3v/udp3JB208e7C4u66v9+uZ//ud/RnJ+VMr6Si5c/NjGYX35/ve/ryKikydP1ltvvVV37drlqZyf9heal+TB5MF+Pq9XcZlfTU1NKiI6depUXblype7Zs8dTuaDtJ367I34Tv5O2vhC/id+FPjfzqzSPPfaYioieeuqp+q1vfUu7urpcH4ZqVer8Mpz+16FSxlGxffnpM64r+RfH79Muuugi/fd//3cdHBwsWias+++8vFc1WBxxiy1er6m6bfMiTv1r/mfFuXPn6r333uvpRt8w7690my/2GGbnZV0xrxW7L9Pr/oLcv+lHXOLZo48+qiLHH+59ww036FNPPRV6PLOWCbqWljpXRU7c6Gzq81pHEHHp3wcffFBFRP/sz/5Mb7nlFv3Vr36lx44dK1rOT/vtx5vzyvDy3jjFj6qqKhURvfDCC3Xt2rV64MCBomXCjB+cW3Ju6efzehGn+WXavmDBAn3wwQdH5X426w/5WX574xC/yc+K1xFEXPqX/Mx5P5UQO1TjFT/Iz8jPCn3uSpxjcZpfpu3kZ+RnBvlZ8TqCiEv/kp8576cSYodq4YdJpP5/5zltbW3S0NAgts2RSaVSIsdbNyr1hWF4eFhuu+02Wb9+/ajW29DQICIira2to1qvk87OTrn00kvl1FNP9VwmTu1PitGer4W8+OKLIiIyb948z2Xi1P6xLk7z88knn5S//uu/lokTJ3ouE6f2A3ZxGp/E73iIU/wjfle2OM1P4jeSJi7jU1Wlo6NDvvSlL8kpp5ziuVxc2h+l3t5eOfnkk2XmzJkjtn/qU58aE3GqEo5BKpWS1tZWqa+vL2s73njjDenv75eLL77YV7m4tD9J4rQ+Pf7447J48WLOjypUXObn8PCw7N69Wy677DKprq72XC4u7QecxGV8vvvuu7Jnzx5ZsmSJVFVVeS4Xl/YnSZziH/G7ssVlfhK/kURxGZ8ffvih/OxnP5PLL79cTjrpJM/l4tL+saQSrivF6fuo5557TiZNmiSzZ8/2XCZO7Y+jOB2f119/XQ4ePCh/9Vd/5blMnNpfSKXdlxmXePDBBx/IT3/6U/nKV74i48aN81wuLu2Pq7gcn//5n/+Rp59+Wr70pS9xPlCB4rT+/u53v5P33ntPFixY4LlMnNoP2MVpfL744ouSSqVk7ty5nsvEqf2FkJ8FQ34WjbgcH/Kzyhan9Zf8DEkTp/FJfhYfcYl/5GfRiMvxIT+rbAXW35trytGgSrd161ZZunRpuZtRVul0utxNQMz4+SNUoJArr7yy3E0AEov4DTviN8JC/AaikUql5Jprril3M2Knvb1dli1b5vja1KlTJZvNjnKLRh/HwJ8ZM2bIjBkzyt0MxMzVV19d7iYgASZOnChXXHFFuZsBJNLpp58ul19+ebmbgZghfiMMxG8gOuPHj2etrgBcV/Jv4cKF5W4CInT22WfL2WefXe5mIEZOOukk7q1IsAkTJshXvvKVcjcDCTBnzpxyNwFILO5ngx35WbKRnyEs5GdAdMjPYEd+lmzkZ8nl/b/yicDg4KDjv+OoqalJUqmUpFIp6e/vlyVLlpS7SQAAAAAAAGNOW1ubtLS0SH9/f9723t5e2bp1q+vN8EnCMQAAAAAAAEAQXFcCxoZKui8TAABgLCA/AwAAiBfyMwBjTVkfJjF16lTHf8fRzJkzRURk48aNctddd5W5NQAAAAAAAGPTli1b5NRTT5U1a9bkHvzZ1NQkBw4ckBtuuKHczRsVHAMAAAAAAAAEwXUlYGyopPsyAQAAxgLyMwAAgHghPwMw1tSUs3JVLWf1vtxwww18aQoAAAAAAFBmEydOlGXLlsmyZctk/fr15W5OWXAMAAAAAAAAEATXlYCxoZLuywQAABgLyM8AAADihfwMwFhTVe4GAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDw8TAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACBBeJgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAgvAwCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAThYRIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJwsMkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEoSHSQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACQID5MAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABIEB4mAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAkCA8TAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACBBeJgEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAgvAwCQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAThYRIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJUuP2wte+9rXRbAc82LZtm9TX15e7GSVpa2uTjz76qNzNSIxt27aVuwmhYL0pP9YXIDrML9gRvxEW1hcgOswvAEZDQ4P86Ec/KnczEoP1FTiB9QWIDvMrXMRv4ATWFyA6zC/Y8X1astG/SCriWbLRv+VH/ACiw/xCUhG/k43+LT/iBxAd5heSividbPRv+RWKH9V33HHHHdYNU6ZMkT/84Q+iqlG3Cz7NnTtXGhoa5FOf+lS5mxLI+PHj5eOPPy53MxJl7ty5cs0118hll11W7qYEwnoTH6wvQHSYX7AjfiMsrC9AdJhfQDguuOACWbFihUyYMKHcTQnkww8/lOnTp5e7GYnC+oqwsL4A0WF+wY74jbCwvgDRYX4hifg+LdnoXzghniUb/YswED+A6DC/4IT4nWz0L8JA/ACiw/yCE+J3stG/CEOB+PFESlmVAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAkuLmqnK3AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOHhYRIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJwsMkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEoSHSQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACTI/wFQXI62xN3SYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(mnist_model, to_file='mnist_blocks.png', show_shapes=False, rankdir='LR',show_layer_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'> \n",
    " [plot_model](https://keras.io/visualization/#training-history-visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "¿Cuántos parámetros tiene el modelo de red neuronal que implementaste? \n",
    "\n",
    "Puedes responder a esta pregunta usando el atributo summary(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 26, 26, 28)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 26, 26, 28)        112       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 9, 9, 15)          10515     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 9, 9, 15)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 9, 9, 15)          60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 4, 4, 15)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 4, 4, 20)          1220      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 4, 4, 20)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 4, 20)          1620      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 4, 4, 20)          80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 25)                1025      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 25)                100       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                260       \n",
      "_________________________________________________________________\n",
      "CNN_Cifar10Model (Activation (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 18,752\n",
      "Trainable params: 18,456\n",
      "Non-trainable params: 296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Compila el modelo seleccionando un optimizador (con una tasa de aprendizaje seleccionable, es decir, no uses los valores por defecto), la función de costo (loss) y una metrica adecuadas para este problema.\n",
    "\n",
    "Hint: en la clase 10 revisamos un problema similar, puedes consultar la función de costo y la métrica utilizada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.0, nesterov=False)\n",
    "\n",
    "loss_function = 'categorical_crossentropy'\n",
    "metric_function = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model.compile(optimizer = optimizer, loss = loss_function, metrics = [metric_function])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Entrena la red neuronal que implementaste, indica la cantidad de datos a usar para validar el modelo, el número de epocas a utilizar así como el tamaño del batch. No olvides usar shuffle=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 544s 12ms/step - loss: 0.7097 - accuracy: 0.7734 - val_loss: 1.9015 - val_accuracy: 0.4118\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 538s 12ms/step - loss: 0.3198 - accuracy: 0.9019 - val_loss: 0.1716 - val_accuracy: 0.9442\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 539s 12ms/step - loss: 0.2445 - accuracy: 0.9258 - val_loss: 0.1501 - val_accuracy: 0.9514\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 540s 12ms/step - loss: 0.2058 - accuracy: 0.9381 - val_loss: 0.1342 - val_accuracy: 0.9568\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 543s 12ms/step - loss: 0.1807 - accuracy: 0.9444 - val_loss: 0.1315 - val_accuracy: 0.9626\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 594s 13ms/step - loss: 0.1699 - accuracy: 0.9488 - val_loss: 0.1092 - val_accuracy: 0.9654\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 574s 13ms/step - loss: 0.1588 - accuracy: 0.9524 - val_loss: 0.1288 - val_accuracy: 0.9610\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 532s 12ms/step - loss: 0.1466 - accuracy: 0.9562 - val_loss: 0.0977 - val_accuracy: 0.9702\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 529s 12ms/step - loss: 0.1390 - accuracy: 0.9593 - val_loss: 0.1084 - val_accuracy: 0.9660\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 526s 12ms/step - loss: 0.1317 - accuracy: 0.9607 - val_loss: 0.1026 - val_accuracy: 0.9678\n"
     ]
    }
   ],
   "source": [
    "validation_portion = 0.1\n",
    "batch_size = 100\n",
    "num_epochs = 10 #Solo 10 épocas porque tardaba mucho, pero aprendía rápido\n",
    "\n",
    "history = mnist_model.fit(x=train_x, y=train_y, epochs=num_epochs, batch_size=batch_size, \\\n",
    "                            validation_split=validation_portion, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Grafica el costo en función de la epoca para los conjuntos de entrenamiento y de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuAklEQVR4nO3deXiddZ3//+c7J3vSLdsBmq5QWpqWbqEoiLbK1x+MCIIwUJWxg8LAiMugqDgOMMzMdxa5/CIqKiIyg0iHSy2isgnKgMMM0NZS6QalLTR0T7qkbbaTvH9/3HeSk/QkzXZyZ3k9rutc931/7uW8z2lzXue+78+5b3N3REREOsuIugARERmaFBAiIpKSAkJERFJSQIiISEoKCBERSUkBISIiKSkgRAaAmd1gZnvM7IiZFQ/i837NzO4brOeT0UUBISOKmX3MzFaFH9S7zOwJM3tPP7e53czO72Z+FvBN4IPuXuju1f15vm6eZ4mZVSW3ufv/dfdPp+P5RBQQMmKY2U3AXcD/BeLAZOAe4JI0P3UcyAXWp/l5RAaVAkJGBDMbB9wBfMbdf+HuR929yd1/5e43h8vkmNldZrYzfNxlZjnhvBIz+7WZHTSzGjN7wcwyzOxBgqD5VbhX8uVOz3s6sDmcPGhmvzOzqWbmZpaZtNxzZvbpcHy5mf3BzO40swNmts3MLkxatsjMfhzWeMDMHjWzAuAJ4JSwjiNmdoqZ3W5mP0la92IzWx++jufM7IykedvN7Etmts7MDpnZf5pZ7sD+S8hIooCQkeLdBN/iV3azzN8C7wLmA/OAxcDXw3lfBKqAUoI9gq8B7u5XA28DHw4PH/1b8gbd/XWgIpwc7+7v72G9ZxMESwnwb8CPzMzCeQ8C+eF2y4D/5+5HgQuBnWEdhe6+M3mDYVg9DHwhfB2PEwRbdtJifw5cAEwDzgSW97BeGYUUEDJSFAP73T3RzTIfB+5w973uvg/4e+DqcF4TcDIwJdzzeMHTe6Gyt9z9h+7eDPx7+NxxMzuZIAiud/cDYS3/1cNtXgn8xt1/6+5NwJ1AHnBO0jJ3u/tOd68BfkUQliIpKSBkpKgGSpIP66RwCvBW0vRbYRvAN4AtwNNmttXMvpqeMtvsbh1x92PhaCEwCahx9wN92GaH1+fuLcAOYGKq5wWOhc8pkpICQkaK/wHqgY90s8xOYErS9OSwDXevdfcvuvt04MPATWb2gXC53u5JHA2H+UltJ/Vw3R1AkZmNTzHvRHV0eH3hIatJwDs9fG6RDhQQMiK4+yHgVuC7ZvYRM8s3sywzu9DMWs8bPAx83cxKzawkXP4nAGZ2kZmdFn6oHgaawwfAHmB6L2rZR/Ch/Akzi5nZNcCpPVx3F8HJ6HvMbEL4Gt6bVEdxeEI+lUeAD5nZB8Kut18EGoAXe1q7SDIFhIwY7v5N4CaCE8/7CL6N3wg8Gi7yj8AqYB3wJ2BN2AYwA3gGOEKwN3KPuz8XzvtngmA5aGZf6mE51wI3Exz6qqB3H9JXE5wT2QTsJTjpjLtvIgi5rWEtpySv5O6bgU8A3wb2E+wJfdjdG3vx3CJtTDcMEhGRVLQHISIiKSkgREQkJQWEiIikpIAQEZGUuvtR0bBTUlLiU6dOjboMEZFhY/Xq1fvdvTTVvBEVEFOnTmXVqlVRlyEiMmyY2VtdzdMhJhERSUkBISIiKSkgREQkpRF1DkJERo6mpiaqqqqor6+PupQRITc3l/LycrKysnq8jgJCRIakqqoqxowZw9SpU2m/l5L0hbtTXV1NVVUV06ZN6/F6OsQkIkNSfX09xcXFCocBYGYUFxf3em9MASEiQ5bCYeD05b1UQDQ3wQvfhDd/F3UlIiJDigIiIxNevBs2/DLqSkRkCKmurmb+/PnMnz+fk046iYkTJ7ZNNzZ2f4uNVatW8bnPfW6QKk0fnaQ2g7IK2LM+6kpEZAgpLi5m7dq1ANx+++0UFhbypS+13y8qkUiQmZn6I7SyspLKysrBKDOttAcBEK+AvRuhpSXqSkRkCFu+fDk33XQTS5cu5Stf+Qovv/wy55xzDgsWLOCcc85h8+bNADz33HNcdNFFQBAu11xzDUuWLGH69OncfffdUb6EXtEeBAQB0XgEDr4FRT3vAiYig+Pvf7WeDTsPD+g2Z58ylts+XNHr9V5//XWeeeYZYrEYhw8f5vnnnyczM5NnnnmGr33ta/z85z8/bp1Nmzbx+9//ntraWmbOnMkNN9zQq98jREUBAUFAQHCYSQEhIt244ooriMViABw6dIhPfvKTvPHGG5gZTU1NKdf50Ic+RE5ODjk5OZSVlbFnzx7Ky8sHs+w+UUAAlM4CDPZugDMuiroaEemkL9/006WgoKBt/O/+7u9YunQpK1euZPv27SxZsiTlOjk5OW3jsViMRCKR7jIHhM5BAOQUBnsOe16LuhIRGUYOHTrExIkTAXjggQeiLSYNFBCtymarJ5OI9MqXv/xlbrnlFs4991yam5ujLmfAmbtHXcOAqays9D7fMOj3/wzP/xvc8g5k5w9sYSLSaxs3buSMM86IuowRJdV7amar3T1ln1ztQbSKV4C3wL5NUVciIjIkKCBaJfdkEhERBUSbCVMhKz/oySQiIgqINhkxKDtDPZlEREIKiGStPZlG0Il7EZG+SltAmNn9ZrbXzFJ+JTezm81sbfh4zcyazawonLfdzP4Uzutjt6Q+iM+BY9VwZO+gPaWIyFCVzj2IB4ALuprp7t9w9/nuPh+4Bfgvd69JWmRpOH/wLonYdqJah5lERrslS5bw1FNPdWi76667+Ou//usul2/tZv9nf/ZnHDx48Lhlbr/9du68885un/fRRx9lw4b2c6G33norzzzzTC+rHxhpCwh3fx6oOeGCgWXAw+mqpcfUk0lEQsuWLWPFihUd2lasWMGyZctOuO7jjz/O+PHj+/S8nQPijjvu4Pzzz+/Ttvor8nMQZpZPsKeRfAlEB542s9Vmdt0J1r/OzFaZ2ap9+/b1r5j8IhhzsnoyiQiXX345v/71r2loaABg+/bt7Ny5k5/+9KdUVlZSUVHBbbfdlnLdqVOnsn//fgD+6Z/+iZkzZ3L++ee3XQ4c4Ic//CFnnXUW8+bN46Mf/SjHjh3jxRdf5LHHHuPmm29m/vz5vPnmmyxfvpyf/exnADz77LMsWLCAuXPncs0117TVNnXqVG677TYWLlzI3Llz2bRpYH7PNRQu1vdh4L87HV461913mlkZ8Fsz2xTukRzH3e8F7oXgl9T9riZeoUNMIkPNE1+F3X8a2G2eNBcu/JcuZxcXF7N48WKefPJJLrnkElasWMGVV17JLbfcQlFREc3NzXzgAx9g3bp1nHnmmSm3sXr1alasWMEf//hHEokECxcuZNGiRQBcdtllXHvttQB8/etf50c/+hGf/exnufjii7nooou4/PLLO2yrvr6e5cuX8+yzz3L66afzF3/xF3zve9/jC1/4AgAlJSWsWbOGe+65hzvvvJP77ruv329R5HsQwFV0Orzk7jvD4V5gJbB40Kopmw37Ngf3qhaRUS35MFPr4aVHHnmEhQsXsmDBAtavX9/hcFBnL7zwApdeein5+fmMHTuWiy++uG3ea6+9xnnnncfcuXN56KGHWL+++0PbmzdvZtq0aZx++ukAfPKTn+T559u/N1922WUALFq0iO3bt/f1JXcQ6R6EmY0D3gd8IqmtAMhw99pw/IPAHYNWVHwONDdC9ZtQNmvQnlZEutHNN/10+shHPsJNN93EmjVrqKurY8KECdx555288sorTJgwgeXLl1NfX9/tNswsZfvy5ct59NFHmTdvHg888ADPPfdct9s50XXzWi8pPpCXE09nN9eHgf8BZppZlZl9ysyuN7Prkxa7FHja3Y8mtcWBP5jZq8DLwG/c/cl01Xkc9WQSkVBhYSFLlizhmmuuYdmyZRw+fJiCggLGjRvHnj17eOKJJ7pd/73vfS8rV66krq6O2tpafvWrX7XNq62t5eSTT6apqYmHHnqorX3MmDHU1tYet61Zs2axfft2tmzZAsCDDz7I+973vgF6pamlbQ/C3U94qt/dHyDoDpvcthWYl56qeqDkdMjIDHoyzb38xMuLyIi2bNkyLrvsMlasWMGsWbNYsGABFRUVTJ8+nXPPPbfbdRcuXMiVV17J/PnzmTJlCuedd17bvH/4h3/g7LPPZsqUKcydO7ctFK666iquvfZa7r777raT0wC5ubn8+Mc/5oorriCRSHDWWWdx/fXXH/ecA0mX+07lnnfD+Mnwsf/s/7ZEpE90ue+Bp8t9D4R4hX4LISKjngIilbLZcGgH1B2MuhIRkcgoIFKJzwmGezdGW4fIKDeSDoFHrS/vpQIiFfVkEolcbm4u1dXVCokB4O5UV1eTm5vbq/WGwi+ph56xp0DuOJ2HEIlQeXk5VVVV9PsSOgIEgVteXt6rdRQQqZgFh5l0TSaRyGRlZTFt2rSoyxjVdIipK/EK2LMBWlqirkREJBIKiK6UzYbGWjj0dtSViIhEQgHRldaeTHt0mElERicFRFfKwl8b6kS1iIxSCoiu5BTChKnq6ioio5YCojvqySQio5gCojvxCqjeAk11UVciIjLoFBDdKZsN3gL7Bub+riIiw4kCojttPZl0olpERh8FRHeKpkFmnrq6isiopIDoTkYsuC+1ejKJyCiUzntS329me80s5aermS0xs0NmtjZ83Jo07wIz22xmW8zsq+mqsUd08yARGaXSuQfxAHDBCZZ5wd3nh487AMwsBnwXuBCYDSwzs9lprLN78TlwbD8c2RtZCSIiUUhbQLj780BNH1ZdDGxx963u3gisAC4Z0OJ6oyzMJh1mEpFRJupzEO82s1fN7AkzC+/Sw0RgR9IyVWFbSmZ2nZmtMrNVablufNvNg3SYSURGlygDYg0wxd3nAd8GHg3bLcWyXd5Syt3vdfdKd68sLS0d+CoLSqDwJPVkEpFRJ7KAcPfD7n4kHH8cyDKzEoI9hklJi5YDOyMosV18tg4xicioE1lAmNlJZmbh+OKwlmrgFWCGmU0zs2zgKuCxqOoEgsNM+zZDcyLSMkREBlPabjlqZg8DS4ASM6sCbgOyANz9+8DlwA1mlgDqgKs8uDt5wsxuBJ4CYsD97h7tCYD4HGhugJo3oXRmpKWIiAyWtAWEuy87wfzvAN/pYt7jwOPpqKtPknsyKSBEZJSIuhfT8FA6EyymnkwiMqooIHoiMwdKTldPJhEZVRQQPRWfrT0IERlVFBA9Fa+AQ29D/aGoKxERGRQKiJ5qvTfE3o3R1iEiMkgUED2lazKJyCijgOipceWQM07nIURk1FBA9JRZeG8I9WQSkdFBAdEbrT2ZvMtrB4qIjBgKiN6IV0BjLRx8O+pKRETSTgHRG209mXSYSURGPgVEb5SdEQzVk0lERgEFRG/kjIHxU9STSURGBQVEb8XnqCeTiIwKCojeildA9RvQVB91JSIiaaWA6K34bPAW2Lcp6kpERNJKAdFb6skkIqOEAqK3iqZDZq5OVIvIiJe2gDCz+81sr5ml7BNqZh83s3Xh40Uzm5c0b7uZ/cnM1prZqnTV2CcZMSidpa6uIjLipXMP4gHggm7mbwPe5+5nAv8A3Ntp/lJ3n+/ulWmqr+/Uk0lERoG0BYS7Pw/UdDP/RXc/EE7+L1CerloGXLwCju6FI3ujrkREJG2GyjmITwFPJE078LSZrTaz6yKqqWvx1ntD6DyEiIxcmVEXYGZLCQLiPUnN57r7TjMrA35rZpvCPZJU618HXAcwefLktNcLdOzJdOrSwXlOEZFBFukehJmdCdwHXOLu1a3t7r4zHO4FVgKLu9qGu9/r7pXuXllaWprukgMFJVAY1x6EiIxokQWEmU0GfgFc7e6vJ7UXmNmY1nHgg8DQ6zJUNls9mURkREvbISYzexhYApSYWRVwG5AF4O7fB24FioF7zAwgEfZYigMrw7ZM4Kfu/mS66uyzeAW8ch80JyAW+ZE6EZEBl7ZPNndfdoL5nwY+naJ9KzDv+DWGmPgcSNRDzVYoPT3qakREBtxQ6cU0/LT1ZNJhJhEZmRQQfVUyEyymazKJyIilgOirrFwomaGeTCIyYikg+kM9mURkBFNA9Ee8Ag6+DfWHo65ERGTAKSD6o+0X1RujrUNEJA0UEP2hnkwiMoIpIPpj3CTIGaueTCIyIikg+sMsOA+hnkwiMgIpIPqrbHZw8yD3qCsRERlQCoj+ildAwyE4VBV1JSIiA0oB0V+tPZl0mElERhgFRH+VnREM1ZNJREYYBUR/5Y6F8ZPVk0lERpweBYSZPdiTtlErPkeHmERkxOnpHkRF8oSZxYBFA1/OMFU2G/a/AYmGqCsRERkw3QaEmd1iZrXAmWZ2OHzUAnuBXw5KhcNBvAK8GfZtjroSEZEB021AuPs/u/sY4BvuPjZ8jHH3Yne/ZZBqHPrUk0lERqCeHmL6tZkVAJjZJ8zsm2Y2JY11DS9F0yGWo55MIjKi9DQgvgccM7N5wJeBt4D/6G4FM7vfzPaaWcpPTQvcbWZbzGydmS1MmneBmW0O5321hzVGJ5YJZbPUk0lERpSeBkTC3R24BPiWu38LGHOCdR4ALuhm/oXAjPBxHUEItZ4A/244fzawzMxm97DO6Kgnk4iMMD0NiFozuwW4GvhN+CGe1d0K7v48UNPNIpcA/+GB/wXGm9nJwGJgi7tvdfdGYEW47NBWNhuO7IGj+6OuRERkQPQ0IK4EGoBr3H03MBH4Rj+feyKwI2m6Kmzrqj0lM7vOzFaZ2ap9+/b1s6R+iIc9gbUXISIjRI8CIgyFh4BxZnYRUO/u3Z6D6AFL9VTdtHdV273uXunulaWlpf0sqR/Uk0lERpie/pL6z4GXgSuAPwdeMrPL+/ncVcCkpOlyYGc37UNbYSkUlCogRGTEyOzhcn8LnOXuewHMrBR4BvhZP577MeBGM1sBnA0ccvddZrYPmGFm04B3gKuAj/XjeQZPvAL2KiBEZGToaUBktIZDqJoT/wr7YWAJUGJmVcBthCe23f37wOPAnwFbgGPAX4bzEmZ2I/AUEAPud/fh8akbnwOv3ActzZARi7oaEZF+6WlAPGlmTwEPh9NXEnzAd8ndl51gvgOf6WLe4yfa/pBUNhsS9VCzFUpmRF2NiEi/dBsQZnYaEHf3m83sMuA9BCeR/4fgpLUkS+7JpIAQkWHuRCep7wJqAdz9F+5+k7v/DcG3+7vSW9owVDoLLEMnqkVkRDhRQEx193WdG919FTA1LRUNZ1m5UHyaAkJERoQTBURuN/PyBrKQEUM9mURkhDhRQLxiZtd2bjSzTwGr01PSMBevgAPboaE26kpERPrlRL2YvgCsNLOP0x4IlUA2cGka6xq+ysIT1Xs3wqTF0dYiItIP3QaEu+8BzjGzpUB4LQl+4+6/S3tlw1VyTyYFhIgMYz36HYS7/x74fZprGRnGT4bsMTpRLSLDXk+v5io9ZQbx2QoIERn2FBDp0NqTybu8CK2IyJCngEiHeAXUH4LD70RdiYhInykg0qFMNw8SkeFPAZEO8fAW2goIERnGFBDpkDsOxk1WQIjIsKaASBf1ZBKRYU4BkS7xCqh+AxINUVciItInCoh0iVdASwL2vx51JSIifaKASBf1ZBKRYS6tAWFmF5jZZjPbYmZfTTH/ZjNbGz5eM7NmMysK5203sz+F81als860KD4NYtkKCBEZtnp6T+peM7MY8F3g/wBVBJcOf8zdN7Qu4+7fAL4RLv9h4G/cvSZpM0vdfX+6akyrWGZwhzkFhIgMU+ncg1gMbHH3re7eCKwALulm+WXAw2msZ/DFKxQQIjJspTMgJgI7kqarwrbjmFk+cAHw86RmB542s9Vmdl1XT2Jm15nZKjNbtW/fvgEoewDFK+DIbjhaHXUlIiK9ls6AsBRtXV297sPAf3c6vHSuuy8ELgQ+Y2bvTbWiu9/r7pXuXllaWtq/igda670hdAtSERmG0hkQVcCkpOlyYGcXy15Fp8NL7r4zHO4FVhIcshpe1JNJRIaxdAbEK8AMM5tmZtkEIfBY54XMbBzwPuCXSW0FZjamdRz4IPBaugo91pjA03Fp7sIyyC9RQIjIsJS2gHD3BHAj8BSwEXjE3deb2fVmdn3SopcCT7v70aS2OPAHM3sVeJngNqdPpqPOg8caueQ7/809z7058Bs304lqERm20tbNFcDdHwce79T2/U7TDwAPdGrbCsxLZ22txuVlMevksdz59GbmTBzH+04f4PMY8QpY9WNoaYaM2MBuW0QkjUb9L6nNjH/96FxmxsfwuYf/yI6aYwP7BPEKSNTBge0Du10RkTQb9QEBkJ+dyQ+uXoS7c92Dq6lrbB64jbf2ZNqTtlMoIiJpoYAITSku4FvLFrBp92Fu+cW6gTtpXToLLEPnIURk2FFAJFk6s4ybzj+dR9fu5IEXtw/MRrPyoOhUBYSIDDsKiE4+s/Q0zj8jzj/+ZiMvbR2gX0CrJ5OIDEMKiE4yMoxvXjmPKUX5fOana9h1qK7/G41XwIFt0HCk/9sSERkkCogUxuZm8YOrF1HX2MwNP1lDQ6KfJ63bLrmxsf/FiYgMEgVEF2bEx3DnFfNYu+Mgtz+24cQrdEfXZBKRYUgB0Y0L557MDUtO5eGX32bFy2/3fUPjJkN2oc5DiMiwooA4gS99cCbnzSjh1l+uZ+2Og33bSEYGlM1WQIjIsKKAOIFYhnH3VQsoG5vDDT9Zzf4jDX3bUGtPpnRcFFBEJA0UED0woSCb739iETVHG/nMQ2toam7p/UbiFVB/EA53dcVzEZGhRQHRQ3MmjuNfPjqXl7bV8C9PbOr9BuK6N4SIDC8KiF64dEE5y8+Zyo/+sI1frn2ndyuXzQ6G6skkIsOEAqKX/vZDZ7B4ahFf+fk6Nu463PMV88bD2HLtQYjIsKGA6KWsWAbf+fgCxuVl8VcPrubgscaer6xLbojIMKKA6IOyMbnc8/FF7DpUx+dXrKW5pYc9k+IVsP91SPQiVEREIqKA6KNFUyZw+8UV/Nfr+7jrmdd7tlK8AloSQUiIiAxxCoh++Njiyfx5ZTnf/t0Wnlq/+8QrqCeTiAwjaQ0IM7vAzDab2RYz+2qK+UvM7JCZrQ0ft/Z03aHAzLjjkjnMKx/HFx95lS17T3C11uLTIJatnkwiMiykLSDMLAZ8F7gQmA0sM7PZKRZ9wd3nh487erlu5HKzYnzvE4vIyczgrx5cxZGGRNcLx7KgZKb2IERkWEjnHsRiYIu7b3X3RmAFcMkgrDvoThmfx7c/toDt1cf40iOvdn+7UvVkEpFhIp0BMRHYkTRdFbZ19m4ze9XMnjCzil6ui5ldZ2arzGzVvn37BqLuPjnn1BJuuXAWT67fzT3Pvdn1gvEKqN0Fx2oGrzgRkT5IZ0BYirbOX63XAFPcfR7wbeDRXqwbNLrf6+6V7l5ZWlra11oHxKfeM40PzzuFO5/ezPOvdxFW8fBImfYiRGSIS2dAVAGTkqbLgQ5XqnP3w+5+JBx/HMgys5KerDsUmRn/+tG5zIyP4bMP/5EdNceOXyg+JxgqIERkiEtnQLwCzDCzaWaWDVwFPJa8gJmdZGYWji8O66nuybpDVX52Jj+4ehHuznUPrqausdPtSgvjkF+snkwiMuSlLSDcPQHcCDwFbAQecff1Zna9mV0fLnY58JqZvQrcDVzlgZTrpqvWgTaluIBvLVvApt2HueUX6zqetDbTzYNEZFjITOfGw8NGj3dq+37S+HeA7/R03eFk6cwy/ub80/nmb19n3qTx/OW509pnxufAmn+HlpbgbnMiIkOQPp3S6Malp3H+GXH+8TcbeWlrdfuMeAU0HYMD26IrTkTkBBQQaZSRYXzzynlMKcrnMz9dw+5D9cEM9WQSkWFAAZFmY3Oz+MHVi6hrbOb6n6ymIdEMpWcApoAQkSFNATEIZsTHcOcV81i74yB//6sNkJ0PxaeqJ5OIDGkKiEFy4dyTuWHJqfz0pbf5z1feVk8mERnyFBCD6EsfnMl5M0r4u0fXsyvvNKjZBo1Hoy5LRCQlBcQgimUYd1+1gLKxOdy1Lgtw2Lsp6rJERFJSQAyyCQXZfP8Ti1hdfzIAzbv/FHFFIiKpKSAiMGfiOP760g9w1HNY/fIfoi5HRCQlBURELls0mZrC02jetZ5frn0n6nJERI6jgIjQxNMrmZO5g6/8/FU27jocdTkiIh0oICKUcdIcxngtp+XW8lcPrubgscaoSxIRaaOAiFI8uIHe/1uSza5DdXx+xdrgl9YiIkNAWq/mKicQXpNphr/F7Rdfyt+ufI0zb3+ahZMnsHhaEWdPL2LBpAnkZcciLlRERiMFRJTyJsDYibBnPR+77PNMHJ/H86/v56Vt1dz9uzfwZyErZswrHx8GRjGLpkygMEf/bCKSfvqkiVq8AvZuwMxYMrOMJTPLADhU18Tqt2p4aVsNL22t4QfPb+We594klmHMOWVsEBjTijlrahHj8rMifhEiMhIpIKJWNhve/D0kGiEzu615XF4W758V5/2z4gAcbUiw5u0DvBwGxr+/+BY/fGEbZjDrpLGcPa2Is6cVcda0IkoKc6J6NSIygiggohafAy1NUP1G20nrVApyMjlvRinnzSgFoL6pmbU7DgaBsa2aFa+8zQMvbgfgtLJCzp5WxOJpRbxrejHxsbmD8UpEZIRJa0CY2QXAt4AYcJ+7/0un+R8HvhJOHgFucPdXw3nbgVqgGUi4e2U6a41Mayjs2dBtQHSWmxXjXdOLedf0YmAGjYkW/vTOobbA+OXanTz00tsATCnODwOjmLOnFVE+IQ8zS8OLEZGRJG0BYWYx4LvA/wGqgFfM7DF335C02Dbgfe5+wMwuBO4Fzk6av9Td96erxiGhZAZkZMGe14Ar+ryZ7MwMFk2ZwKIpE7hhyakkmlvYuKuWl7ZV89K2Gp7esIdHVlUBcMq4XM6eXhyexyhiWkmBAkNEjpPOPYjFwBZ33wpgZiuAS4C2gHD3F5OW/1+gPI31DE2xLCidOeD3hsiMZTC3fBxzy8fx6fOm09LivL63tu0cxgtv7GflH4NLfJSOyWkLi7OnFTOjrJCMDAWGyGiXzoCYCOxImq6i495BZ58CnkiaduBpM3PgB+5+b6qVzOw64DqAyZMn96vgyMQrYHt6L9qXkWHMOmkss04ay1+8eyruztb9R3l5W00YGtX8Zt0uAMbmZjKluIBJRXmUT8infEJe+Mhn4vg8CtTNVmRUSOdfeqqvoJ5yQbOlBAHxnqTmc919p5mVAb81s03u/vxxGwyC416AysrKlNsf8spmw7r/hGM1kF80KE9pZpxaWsippYUsWzwZd6fqQB0vbath7Y4D7KipY/PuWp7duJeGREuHdYsKsttCY1JbgATDiRPyyM9WgIiMBOn8S64CJiVNlwM7Oy9kZmcC9wEXunt1a7u77wyHe81sJcEhq+MCYkSIzwmGezfA1Pd0v2yamBmTivKZVJTP5Yvaj/S5O/uPNLLjwDGqDtRR1TasY9PuWp7ZuJfGTgFS3BYgYXgU5YdhksfE8fn6ZbjIMJHOgHgFmGFm04B3gKuAjyUvYGaTgV8AV7v760ntBUCGu9eG4x8E7khjrdFK7skUUUB0xcwoHZND6ZgcFk6ecNz8lhZn/9EGdtR0DI+qA8fYuOswv92wh8bmjgFSUpjNxE6HriYlBUpulgJEZChIW0C4e8LMbgSeIujmer+7rzez68P53wduBYqBe8JeNK3dWePAyrAtE/ipuz+ZrlojN+ak4LIbe16LupJey8gwysbkUjYml0VTugiQIw1JeyDtQbJh52F+uz5VgORQPiGPU8bnUlyQw4SCbIoLsikKhxOShlkxXW9SJF3MfXgetk+lsrLSV61aFXUZffPARdBUB9c+G3Ulg6qlxdl3pIEdNccfwtp5qI4DRxs5WNdEV/9Nx+ZmUlyYw4T8LIoKcoIgKcymKD8IlKLC9nApKsjW+RGRTsxsdVe/M9Nfy1ARr4A1D0JLC2SMnm/FGRlGfGwu8bG5VE5NvUyiuYWDdU3UHG2k+kgjB441Un20kZojjdQcbaDmWBM1RxuoOnCMdVUHOXCskabm1ImSm5VBcUEORUl7IkUp9k6C6RzG5Gaqy6+MWgqIoaJsNjQdhYPboWh61NUMKZmxDEoKc4JrTMVPvLy7U9uQoOZIGCRHGzlwtHW8gepwuuZoI1v3HaHmaCPHGlPfhyOWYYzNzSQ3K0ZuVoyczAxysmLkZmaEbeEws308p7U9M9ZxmbAtp0Nb8rZixBRGMoQoIIaK1p5M918AhWXBOYnc8cEw5SNpXlY+6JfQbcyMsblZjM3NYmpJQY/WqW9qpiYMjdYgqTka7JnU1ieob2qmvqklGCaC4cFjjUFbornD/M7dgnsjK2YpQiQIlrzsGDmZHdvzWkMmDK+87FiKYOo4npe0Te0dSXcUEEPFKfNhyS1w4C2oOxA89m1uH29p6nrdWHZ7WKQMlfHHh0reBMgZN6oOZ3UnNyvGKePzOGV8Xr+31dLiNCRawyQpWFpDJNFMQ1On9tbl20Lm+PWONCTYf6SRhqZm6jptr6+nErNjGV0GSfLeTV7nkMkO2vKSx7PbAyh5fm52BtmxDF3OZRhSQAwVGTFY8tXU89yh6Vh7WLQ9DqZoOwCHq4IeUXUHoPFIN09qQWgcFyrjIWcMZBcmDVvHxwTjrW3ZYyCm/0bJMjIs+IAcpN97uDuNzS3UN3bcm2kPkWC6IdFMXWPHQKpraqahUxC1rneorom9ncKorqn5uN+99ESGEQZHJnnZGe3hcVyYpA6ezsvmZmWQnRkET1YsaTwzg6yYKZAGiP6yhwMzyC4IHuN6ebmqRCPUH+w+UOqT2g9sC4YNR7rfa0mWmdcxNHLGJgVIGCzJQZOyLQyezFwdLuslMyMnMzj8NI703zyqpcWpD8OmNTzqGoPwqGtqD6HW8Q7Dpmbqk8brGps5cLSRnW3TQVgda0zQ0s8OllkxI6tzgMSM7MyM9vZwXuuynUMnK5ZBVmYQOO0B1Lpc+/aDNiM7Fgu2lbSd5G13mI5lDPlDfAqIkS4zOzinUVjW+3UTDUFQNNYGw4baYI8keZg8P7ntyG6oTmprOtaz58zIbA+QrDywGFhGcCjMkh+xjtPdzrdgD61P8y2oI28C5BUFw/yi9unccSN7D8odGo8GXyLqD0FDLRk5Y8kfcxL5BRPSFubuTlOzJwVQx1Cpa2ymqbmFxuYWGhMtNDV7MJ0I2pra2oN5DW3j7e2NzU5jItjm4fpU6zpNiRYawul0iGVYh8BoDaQO00mh1r5M+55SViyDcXlZfOn/mzng9Y3g/9nSb5k5waOguP/bamkOwyI5SGo7tR1OGj8S9OpyB2/p+GhpPr6tuamL+Q7e3MX6rdtONT/peRN1wbArueOSDs+lCJEO00nnigbr/E9TffsHfOuj7mCntlTzw3FP3cOLWE7wI8+2x8kdh4Vhe+64XgeJmQXfyDODD7+ouTvNLcGhvKaEHxdCjc3tIdWU6DTdKcTalk90mk5qa5tOCr6jDQkONnvK5RUQMrxlxIIPitxxUVfSey0t0HAoOPR2rPXQXE04XdNxuu4A1GxtP3TXJUvqNNBdqIxvn/aWjh/kyR/i3X3INzd0//oyc4PAav33yS+B4tPap5Pn5RRC/WE4sgdqd0Ht7mC4d2Nw69yGwym2n5cUHPHjg2TMyVAYD/Yah+jhRTMjM2ZkxjIgO2mG+5CteSAoIEROJCOj/Zt/by6229IcfEB3DpFUoXJ0H+x/PTz/k+JDttv6Mjt+iOeOC85VJU+3zQ+HeeEwZyxkDeAtaRuOhOGxu2OA1O4OHrvWwetPB3uHnWUVdAqOFHsmhfEgpFJpaQ6uRpCoD4cNwd5fU33qYaKh0/Iphon6Tut1Wsabw0OcWcG/QywzGI9lhW2x9vHWeRmZYVvSsG28dbnk7SQvl9XpOWLBeE4hzPnowP07hhQQIumSEQv2Anp7CffmpqQOBUmhkpHZ8UO/9UN+KP0OJifsdFB8avfLNdR2HSK1u+Gd1cEwUXf8utljoKAk+HBO/tDuaaeKVGLZwZ5UZm4QmJl57cPs/ODfMDM3OB+VPIxlBcHU0gTNiXDYBC2J4NHcFLS1NLePN4fTifr2ZdvWSdpOS6LjNrs61AdQUKaAEBkVYllQWBo8RqrWXmwlM7pexj3YA2sNkOTDWkf3hR/qOR0/zFuHmTnHf5i3Do8LgdwgzIc6946h05xoD5U0XVNPASEiQ5O1nqcZD2Wzoq4membBl4fY4J20189oRUQkJQWEiIikpIAQEZGUFBAiIpKSAkJERFJSQIiISEoKCBERSUkBISIiKZmn6Rd4UTCzfcBbfVy9BNg/gOUMZ3ovOtL70ZHej3Yj4b2Y4u4pf7Y/ogKiP8xslbtXRl3HUKD3oiO9Hx3p/Wg30t8LHWISEZGUFBAiIpKSAqLdvVEXMITovehI70dHej/ajej3QucgREQkJe1BiIhISgoIERFJadQHhJldYGabzWyLmX016nqiZGaTzOz3ZrbRzNab2eejrilqZhYzsz+a2a+jriVqZjbezH5mZpvC/yPvjrqmKJnZ34R/J6+Z2cNmNoA39x4aRnVAmFkM+C5wITAbWGZms6OtKlIJ4IvufgbwLuAzo/z9APg8sDHqIoaIbwFPuvssYB6j+H0xs4nA54BKd58DxICroq1q4I3qgAAWA1vcfau7NwIrgEsiriky7r7L3deE47UEHwATo60qOmZWDnwIuC/qWqJmZmOB9wI/AnD3Rnc/GGlR0csE8swsE8gHdkZcz4Ab7QExEdiRNF3FKP5ATGZmU4EFwEsRlxKlu4AvAy0R1zEUTAf2AT8OD7ndZ2YFURcVFXd/B7gTeBvYBRxy96ejrWrgjfaAsBRto77fr5kVAj8HvuDuh6OuJwpmdhGw191XR13LEJEJLAS+5+4LgKPAqD1nZ2YTCI42TANOAQrM7BPRVjXwRntAVAGTkqbLGYG7ib1hZlkE4fCQu/8i6noidC5wsZltJzj0+H4z+0m0JUWqCqhy99Y9yp8RBMZodT6wzd33uXsT8AvgnIhrGnCjPSBeAWaY2TQzyyY4yfRYxDVFxsyM4BjzRnf/ZtT1RMndb3H3cnefSvD/4nfuPuK+IfaUu+8GdpjZzLDpA8CGCEuK2tvAu8wsP/y7+QAj8KR9ZtQFRMndE2Z2I/AUQS+E+919fcRlRelc4GrgT2a2Nmz7mrs/Hl1JMoR8Fngo/DK1FfjLiOuJjLu/ZGY/A9YQ9P77IyPwshu61IaIiKQ02g8xiYhIFxQQIiKSkgJCRERSUkCIiEhKCggREUlJASHSC2bWbGZrkx4D9mtiM5tqZq8N1PZE+mtU/w5CpA/q3H1+1EWIDAbtQYgMADPbbmb/amYvh4/TwvYpZvasma0Lh5PD9riZrTSzV8NH62UaYmb2w/A+A0+bWV5kL0pGPQWESO/kdTrEdGXSvMPuvhj4DsGVYAnH/8PdzwQeAu4O2+8G/svd5xFc06j1F/wzgO+6ewVwEPhoWl+NSDf0S2qRXjCzI+5emKJ9O/B+d98aXvBwt7sXm9l+4GR3bwrbd7l7iZntA8rdvSFpG1OB37r7jHD6K0CWu//jILw0keNoD0Jk4HgX410tk0pD0ngzOk8oEVJAiAycK5OG/xOOv0j7rSg/DvwhHH8WuAHa7ns9drCKFOkpfTsR6Z28pCvdQnCP5taurjlm9hLBF69lYdvngPvN7GaCO7K1XgH188C9ZvYpgj2FGwjuTCYyZOgchMgACM9BVLr7/qhrERkoOsQkIiIpaQ9CRERS0h6EiIikpIAQEZGUFBAiIpKSAkJERFJSQIiISEr/Pz8kPjbri946AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Cost function')\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4 color=\"blue\">\n",
    "Un buen fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Grafica el accuracy (la precisión del modelo) en función de la epoca para los conjuntos de entrenamiento y de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.grid()\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    " #### Ejercicio 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Evalua el modelo en el conjunto de prueba. Usa el métodod evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 52s 5ms/step\n",
      "Loss = 0.08060407104715706\n",
      "Test Accuracy = 0.9726999998092651\n"
     ]
    }
   ],
   "source": [
    "evaluations = mnist_model.evaluate(x = test_x, y = test_y)\n",
    "\n",
    "print (\"Loss = \" + str(evaluations[0]))\n",
    "print (\"Test Accuracy = \" + str(evaluations[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color=\"cornflowerblue\">\n",
    "\n",
    "Parte III: **Inferencia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "    \n",
    "#### Ejercicio 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Realiza predicciones sobre el conjunto de prueba. Usa el método predict()\n",
    "\n",
    "Muestra algun ejemplo, es decir dado un input tomado del conjunto test_x muestra cuál es la inferencia realizada por la red neuronal y cual es la etiqueta real (la correspondiente test_y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T01:04:19.728584Z",
     "start_time": "2020-11-25T01:04:19.724692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting the digits associated to each sample in the test set (test_x)\n",
    "predictions = mnist_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 is the digit corresponding to the sample 1234\n",
      "For the sample number 1234 the prediction is the digit: 8\n",
      "\n",
      " This is its image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1234\n",
    "\n",
    "plt.imshow(test_x[index].reshape((28, 28)),cmap='binary')\n",
    "\n",
    "print(np.argmax(test_y[index]), \"is the digit corresponding to the sample\", index)\n",
    "\n",
    "prediction = np.argmax(predictions[index])\n",
    "\n",
    "print('For the sample number', index, 'the prediction is the digit:', prediction)\n",
    "\n",
    "print(\"\\n This is its image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 is the digit corresponding to the sample 1345\n",
      "For the sample number 1345 the prediction is the digit: 2\n",
      "\n",
      " This is its image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1345\n",
    "\n",
    "plt.imshow(test_x[index].reshape((28, 28)),cmap='binary')\n",
    "\n",
    "print(np.argmax(test_y[index]), \"is the digit corresponding to the sample\", index)\n",
    "\n",
    "prediction = np.argmax(predictions[index])\n",
    "\n",
    "print('For the sample number', index, 'the prediction is the digit:', prediction)\n",
    "\n",
    "print(\"\\n This is its image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is the digit corresponding to the sample 9876\n",
      "For the sample number 9876 the prediction is the digit: 1\n",
      "\n",
      " This is its image\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 9876\n",
    "\n",
    "plt.imshow(test_x[index].reshape((28, 28)),cmap='binary')\n",
    "\n",
    "print(np.argmax(test_y[index]), \"is the digit corresponding to the sample\", index)\n",
    "\n",
    "prediction = np.argmax(predictions[index])\n",
    "\n",
    "print('For the sample number', index, 'the prediction is the digit:', prediction)\n",
    "\n",
    "print(\"\\n This is its image\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
